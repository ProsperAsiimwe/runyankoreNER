(runyankore-ner) prosper@badkamer:~/scratch/prosper/runyankoreNER$ ./rq2_train_scripts/Embeddings/CROSS-LINGUAL-TRAINING/lug_hau_nya/train_all_PLMs_combined_dataset.sh
Starting training with AfroXLMR...
/home/prosper/miniconda3/envs/runyankore-ner/lib/python3.10/site-packages/huggingface_hub/file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
09/01/2025 19:44:21 - INFO - __main__ -   Training/evaluation parameters Namespace(data_dir='data/EmbeddingGroups/CROSS-LINGUAL/lug_hau_nya/COMBINED/', model_type='xlmroberta', model_name_or_path='Davlan/afro-xlmr-base', input_dir=None, output_dir='models/EmbeddingGroups/CROSS-LINGUAL/lug_hau_nya/combined_afroxlmr', test_result_file='test_results.txt', test_prediction_file='test_predictions.txt', labels='', config_name='', tokenizer_name='', cache_dir='', max_seq_length=164, do_train=True, do_finetune=False, do_eval=True, do_predict=True, evaluate_during_training=False, do_lower_case=False, per_gpu_train_batch_size=32, per_gpu_eval_batch_size=8, gradient_accumulation_steps=1, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=10.0, max_steps=-1, warmup_steps=0, logging_steps=500, save_steps=5000, eval_all_checkpoints=False, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=1, local_rank=-1, server_ip='', server_port='', n_gpu=1, device=device(type='cuda'))
09/01/2025 19:44:21 - INFO - __main__ -   Creating features from dataset file at data/EmbeddingGroups/CROSS-LINGUAL/lug_hau_nya/COMBINED/
09/01/2025 19:44:21 - INFO - utils_ner -   Writing example 0 of 31909
09/01/2025 19:44:21 - INFO - utils_ner -   *** Example ***
09/01/2025 19:44:21 - INFO - utils_ner -   guid: train-1
09/01/2025 19:44:21 - INFO - utils_ner -   tokens: <s> ▁Ei hanga ▁ry a ▁Ru rash a ▁ni ry o ▁ry a kiri ze yo ▁om u ▁ku gu za ▁e by ama guzi ▁om uri ▁A fi rika ▁a haga ti ▁y ' en kumi ▁i biri ▁i kumi ▁na ▁mush anju ▁n ' en kumi ▁i biri ▁i kumi ▁na ▁ish atu ▁ . </s>
09/01/2025 19:44:21 - INFO - utils_ner -   input_ids: 0 4565 58146 5535 11 4518 41535 11 300 1294 31 5535 11 27531 731 1410 171 34 228 1234 596 28 1272 2887 79255 171 1162 62 1029 14265 10 94562 118 113 25 33 87064 17 35653 17 87064 24 79755 73604 653 25 33 87064 17 35653 17 87064 24 12277 7945 6 5 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
09/01/2025 19:44:21 - INFO - utils_ner -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
09/01/2025 19:44:21 - INFO - utils_ner -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
09/01/2025 19:44:21 - INFO - utils_ner -   label_ids: -100 0 -100 0 -100 7 -100 -100 0 -100 -100 0 -100 -100 -100 -100 0 -100 0 -100 -100 0 -100 -100 -100 0 -100 7 -100 -100 0 -100 -100 1 -100 -100 -100 2 -100 2 -100 2 2 -100 2 -100 -100 -100 2 -100 2 -100 2 2 -100 0 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100
09/01/2025 19:44:21 - INFO - utils_ner -   *** Example ***
09/01/2025 19:44:21 - INFO - utils_ner -   guid: train-2
09/01/2025 19:44:21 - INFO - utils_ner -   tokens: <s> ▁Om ush wij a ▁gw ' en siri ▁gu ka ba ▁ guri ▁mw ingi ▁ , ▁om wa ka ▁og u hwe ire ▁ . </s>
09/01/2025 19:44:21 - INFO - utils_ner -   input_ids: 0 2383 33768 32674 11 13303 25 33 83468 2497 161 402 6 69140 43879 22242 6 4 171 634 161 60 34 67116 2149 6 5 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
09/01/2025 19:44:21 - INFO - utils_ner -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
09/01/2025 19:44:21 - INFO - utils_ner -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
09/01/2025 19:44:21 - INFO - utils_ner -   label_ids: -100 0 -100 -100 -100 0 -100 -100 -100 0 -100 -100 0 -100 0 -100 0 -100 1 -100 -100 2 -100 -100 -100 0 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100
09/01/2025 19:44:21 - INFO - utils_ner -   *** Example ***
09/01/2025 19:44:21 - INFO - utils_ner -   guid: train-3
09/01/2025 19:44:21 - INFO - utils_ner -   tokens: <s> ▁Oku jag uza ▁em yaka ▁maku mi ▁a biri ▁kiri ▁a ha ▁kar enda ▁ . </s>
09/01/2025 19:44:21 - INFO - utils_ner -   input_ids: 0 81370 100462 23332 352 122669 62332 266 10 35653 30420 10 528 1185 7074 6 5 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
09/01/2025 19:44:21 - INFO - utils_ner -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
09/01/2025 19:44:21 - INFO - utils_ner -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
09/01/2025 19:44:21 - INFO - utils_ner -   label_ids: -100 0 -100 -100 1 -100 2 -100 2 -100 0 0 -100 0 -100 0 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100
09/01/2025 19:44:21 - INFO - utils_ner -   *** Example ***
09/01/2025 19:44:21 - INFO - utils_ner -   guid: train-4
09/01/2025 19:44:21 - INFO - utils_ner -   tokens: <s> ▁A keer eka ▁oku ▁e ki tong ore ▁kya tung u uki re ▁om u ▁my aka ▁i kumi ▁e hing wir e ▁ . </s>
09/01/2025 19:44:21 - INFO - utils_ner -   input_ids: 0 62 49776 26228 14770 28 301 18176 4524 30427 8587 34 38662 107 171 34 759 9227 17 87064 28 33059 17084 13 6 5 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
09/01/2025 19:44:21 - INFO - utils_ner -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
09/01/2025 19:44:21 - INFO - utils_ner -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
09/01/2025 19:44:21 - INFO - utils_ner -   label_ids: -100 0 -100 -100 0 0 -100 -100 -100 0 -100 -100 -100 -100 0 -100 1 -100 2 -100 2 -100 -100 -100 0 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100
09/01/2025 19:44:21 - INFO - utils_ner -   *** Example ***
09/01/2025 19:44:21 - INFO - utils_ner -   guid: train-5
09/01/2025 19:44:21 - INFO - utils_ner -   tokens: <s> ▁E bi hem bo ▁by a ▁vidi iyo ▁y ' e by es hong oro ▁by ' om wa ka ▁og u ▁by ' og ye zib we yo ▁ . </s>
09/01/2025 19:44:21 - INFO - utils_ner -   input_ids: 0 241 964 7701 837 390 11 16631 10734 113 25 13 1272 90 30434 12393 390 25 306 634 161 60 34 390 25 1663 1033 120818 1177 1410 6 5 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
09/01/2025 19:44:21 - INFO - utils_ner -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
09/01/2025 19:44:21 - INFO - utils_ner -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
09/01/2025 19:44:21 - INFO - utils_ner -   label_ids: -100 0 -100 -100 -100 0 -100 0 -100 0 -100 -100 -100 -100 -100 -100 1 -100 -100 -100 -100 2 -100 0 -100 -100 -100 -100 -100 -100 0 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100
09/01/2025 19:44:22 - INFO - utils_ner -   Writing example 10000 of 31909
09/01/2025 19:44:24 - INFO - utils_ner -   Writing example 20000 of 31909
09/01/2025 19:44:28 - INFO - utils_ner -   Writing example 30000 of 31909
09/01/2025 19:44:28 - INFO - __main__ -   Saving features into cached file data/EmbeddingGroups/CROSS-LINGUAL/lug_hau_nya/COMBINED/cached_train_afro-xlmr-base_164
/home/prosper/miniconda3/envs/runyankore-ner/lib/python3.10/site-packages/transformers/optimization.py:588: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
09/01/2025 19:44:32 - INFO - __main__ -   ***** Running training *****
09/01/2025 19:44:32 - INFO - __main__ -     Num examples = 31909
09/01/2025 19:44:32 - INFO - __main__ -     Num Epochs = 10
09/01/2025 19:44:32 - INFO - __main__ -     Instantaneous batch size per GPU = 32
09/01/2025 19:44:32 - INFO - __main__ -     Total train batch size (w. parallel, distributed & accumulation) = 32
09/01/2025 19:44:32 - INFO - __main__ -     Gradient Accumulation steps = 1
09/01/2025 19:44:32 - INFO - __main__ -     Total optimization steps = 9980
Epoch:   0%|                                                                                                                                                           | 0/10 [00:00<?, ?it/s/home/prosper/miniconda3/envs/runyankore-ner/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:182: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn(
Iteration: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 998/998 [03:48<00:00,  4.36it/s]
09/01/2025 19:48:21 - INFO - __main__ -   Creating features from dataset file at data/EmbeddingGroups/CROSS-LINGUAL/lug_hau_nya/COMBINED/██████████████████▊| 997/998 [03:48<00:00,  4.16it/s]
09/01/2025 19:48:21 - INFO - utils_ner -   Writing example 0 of 7498
09/01/2025 19:48:21 - INFO - utils_ner -   *** Example ***
09/01/2025 19:48:21 - INFO - utils_ner -   guid: dev-1
09/01/2025 19:48:21 - INFO - utils_ner -   tokens: <s> ▁Eis home ro ▁ry a handi ika ▁ripoti ▁ye ▁er izo oba ▁ . </s>
09/01/2025 19:48:21 - INFO - utils_ner -   input_ids: 0 104331 29552 516 5535 11 146625 2959 187326 2422 72 33602 16159 6 5 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
09/01/2025 19:48:21 - INFO - utils_ner -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
09/01/2025 19:48:21 - INFO - utils_ner -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
09/01/2025 19:48:21 - INFO - utils_ner -   label_ids: -100 0 -100 -100 0 -100 -100 -100 0 0 1 -100 -100 0 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100
09/01/2025 19:48:21 - INFO - utils_ner -   *** Example ***
09/01/2025 19:48:21 - INFO - utils_ner -   guid: dev-2
09/01/2025 19:48:21 - INFO - utils_ner -   tokens: <s> ▁A kasi ngwa ▁om u ▁karu uru ▁om wa ka ▁og uh wa ire ▁ . </s>
09/01/2025 19:48:21 - INFO - utils_ner -   input_ids: 0 62 58801 95560 171 34 102377 12894 171 634 161 60 5951 634 2149 6 5 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
09/01/2025 19:48:21 - INFO - utils_ner -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
09/01/2025 19:48:21 - INFO - utils_ner -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
09/01/2025 19:48:21 - INFO - utils_ner -   label_ids: -100 0 -100 -100 0 -100 0 -100 1 -100 -100 2 -100 -100 -100 0 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100
09/01/2025 19:48:21 - INFO - utils_ner -   *** Example ***
09/01/2025 19:48:21 - INFO - utils_ner -   guid: dev-3
09/01/2025 19:48:21 - INFO - utils_ner -   tokens: <s> ▁Ok w ombe ka ▁o ruti ndo ▁ , ▁ni kwi ija ▁kut wara ▁em yaka ▁es hat u ▁ . </s>
09/01/2025 19:48:21 - INFO - utils_ner -   input_ids: 0 9972 434 54013 161 36 97387 557 6 4 300 96855 4391 28600 63991 352 122669 198 2943 34 6 5 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
09/01/2025 19:48:21 - INFO - utils_ner -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
09/01/2025 19:48:21 - INFO - utils_ner -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
09/01/2025 19:48:21 - INFO - utils_ner -   label_ids: -100 0 -100 -100 -100 0 -100 -100 0 -100 0 -100 -100 0 -100 1 -100 2 -100 -100 0 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100
09/01/2025 19:48:21 - INFO - utils_ner -   *** Example ***
09/01/2025 19:48:21 - INFO - utils_ner -   guid: dev-4
09/01/2025 19:48:21 - INFO - utils_ner -   tokens: <s> ▁Om wo jo ▁aka itwa ▁iba are ▁eru kiri ▁or wab aire ▁or wahi ring itsi re ▁om wa ka ▁og wa ▁h wa ire ▁ . </s>
09/01/2025 19:48:21 - INFO - utils_ner -   input_ids: 0 2383 3613 513 15623 122448 7824 1046 3599 27531 707 72947 9459 707 71387 2852 30241 107 171 634 161 60 634 1096 634 2149 6 5 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
09/01/2025 19:48:21 - INFO - utils_ner -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
09/01/2025 19:48:21 - INFO - utils_ner -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
09/01/2025 19:48:21 - INFO - utils_ner -   label_ids: -100 0 -100 -100 0 -100 0 -100 0 -100 0 -100 -100 0 -100 -100 -100 -100 1 -100 -100 2 -100 2 -100 -100 0 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100
09/01/2025 19:48:21 - INFO - utils_ner -   *** Example ***
09/01/2025 19:48:21 - INFO - utils_ner -   guid: dev-5
09/01/2025 19:48:21 - INFO - utils_ner -   tokens: <s> ▁Om web embe zi ▁w ' ei hanga ▁aka kinga ▁a makan isa ▁okuma ra ▁e bir o ▁maku mi ▁muka aga ▁e bind i ▁ . </s>
09/01/2025 19:48:21 - INFO - utils_ner -   input_ids: 0 2383 14051 55720 708 148 25 1399 58146 15623 107546 10 54082 4542 97405 219 28 5720 31 62332 266 14330 4729 28 89817 14 6 5 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
09/01/2025 19:48:21 - INFO - utils_ner -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
09/01/2025 19:48:21 - INFO - utils_ner -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
09/01/2025 19:48:21 - INFO - utils_ner -   label_ids: -100 0 -100 -100 -100 0 -100 -100 -100 0 -100 0 -100 -100 0 -100 1 -100 -100 2 -100 2 -100 0 -100 -100 0 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100
09/01/2025 19:48:22 - INFO - __main__ -   Saving features into cached file data/EmbeddingGroups/CROSS-LINGUAL/lug_hau_nya/COMBINED/cached_dev_afro-xlmr-base_164
09/01/2025 19:48:23 - INFO - __main__ -   ***** Running evaluation  *****
09/01/2025 19:48:23 - INFO - __main__ -     Num examples = 7498
09/01/2025 19:48:23 - INFO - __main__ -     Batch size = 8
Evaluating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 938/938 [00:25<00:00, 36.47it/s]
eval result:  998 0.75833██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊| 937/938 [00:25<00:00, 32.06it/s]
09/01/2025 19:48:50 - INFO - __main__ -   Saving model checkpoint to models/EmbeddingGroups/CROSS-LINGUAL/lug_hau_nya/combined_afroxlmr
Iteration: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 998/998 [03:46<00:00,  4.40it/s]
09/01/2025 19:52:37 - INFO - __main__ -   Loading features from cached file data/EmbeddingGroups/CROSS-LINGUAL/lug_hau_nya/COMBINED/cached_dev_afro-xlmr-base_164/998 [03:46<00:00,  4.20it/s]
09/01/2025 19:52:37 - INFO - __main__ -   ***** Running evaluation  *****
09/01/2025 19:52:37 - INFO - __main__ -     Num examples = 7498
09/01/2025 19:52:37 - INFO - __main__ -     Batch size = 8
Evaluating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 938/938 [00:25<00:00, 36.84it/s]
eval result:  1996 0.79419█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋| 936/938 [00:25<00:00, 32.62it/s]
09/01/2025 19:53:04 - INFO - __main__ -   Saving model checkpoint to models/EmbeddingGroups/CROSS-LINGUAL/lug_hau_nya/combined_afroxlmr
Iteration: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 998/998 [03:47<00:00,  4.39it/s]
09/01/2025 19:56:51 - INFO - __main__ -   Loading features from cached file data/EmbeddingGroups/CROSS-LINGUAL/lug_hau_nya/COMBINED/cached_dev_afro-xlmr-base_164/998 [03:47<00:00,  5.05it/s]
09/01/2025 19:56:52 - INFO - __main__ -   ***** Running evaluation  *****
09/01/2025 19:56:52 - INFO - __main__ -     Num examples = 7498
09/01/2025 19:56:52 - INFO - __main__ -     Batch size = 8
Evaluating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 938/938 [00:25<00:00, 36.98it/s]
eval result:  2994 0.79505█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋| 936/938 [00:25<00:00, 33.08it/s]
09/01/2025 19:57:19 - INFO - __main__ -   Saving model checkpoint to models/EmbeddingGroups/CROSS-LINGUAL/lug_hau_nya/combined_afroxlmr
Iteration: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 998/998 [03:48<00:00,  4.37it/s]
09/01/2025 20:01:07 - INFO - __main__ -   Loading features from cached file data/EmbeddingGroups/CROSS-LINGUAL/lug_hau_nya/COMBINED/cached_dev_afro-xlmr-base_164/998 [03:48<00:00,  4.22it/s]
09/01/2025 20:01:07 - INFO - __main__ -   ***** Running evaluation  *****
09/01/2025 20:01:07 - INFO - __main__ -     Num examples = 7498
09/01/2025 20:01:07 - INFO - __main__ -     Batch size = 8
Evaluating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 938/938 [00:25<00:00, 37.15it/s]
eval result:  3992 0.78535█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊| 937/938 [00:25<00:00, 33.56it/s]
Iteration: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 998/998 [03:27<00:00,  4.80it/s]
09/01/2025 20:05:01 - INFO - __main__ -   Loading features from cached file data/EmbeddingGroups/CROSS-LINGUAL/lug_hau_nya/COMBINED/cached_dev_afro-xlmr-base_164/998 [03:27<00:00,  5.90it/s]
09/01/2025 20:05:01 - INFO - __main__ -   ***** Running evaluation  *****
09/01/2025 20:05:01 - INFO - __main__ -     Num examples = 7498
09/01/2025 20:05:01 - INFO - __main__ -     Batch size = 8
Evaluating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 938/938 [00:13<00:00, 70.14it/s]
eval result:  4990 0.80949█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████ | 932/938 [00:13<00:00, 60.66it/s]
09/01/2025 20:05:16 - INFO - __main__ -   Saving model checkpoint to models/EmbeddingGroups/CROSS-LINGUAL/lug_hau_nya/combined_afroxlmr
Iteration: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 998/998 [03:44<00:00,  4.44it/s]
09/01/2025 20:09:01 - INFO - __main__ -   Loading features from cached file data/EmbeddingGroups/CROSS-LINGUAL/lug_hau_nya/COMBINED/cached_dev_afro-xlmr-base_164/998 [03:44<00:00,  4.26it/s]
09/01/2025 20:09:01 - INFO - __main__ -   ***** Running evaluation  *****
09/01/2025 20:09:01 - INFO - __main__ -     Num examples = 7498
09/01/2025 20:09:01 - INFO - __main__ -     Batch size = 8
Evaluating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 938/938 [00:17<00:00, 53.04it/s]
eval result:  5988 0.81747█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎| 933/938 [00:17<00:00, 60.76it/s]
09/01/2025 20:09:21 - INFO - __main__ -   Saving model checkpoint to models/EmbeddingGroups/CROSS-LINGUAL/lug_hau_nya/combined_afroxlmr
Iteration: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 998/998 [03:47<00:00,  4.39it/s]
09/01/2025 20:13:08 - INFO - __main__ -   Loading features from cached file data/EmbeddingGroups/CROSS-LINGUAL/lug_hau_nya/COMBINED/cached_dev_afro-xlmr-base_164/998 [03:47<00:00,  4.28it/s]
09/01/2025 20:13:08 - INFO - __main__ -   ***** Running evaluation  *****
09/01/2025 20:13:08 - INFO - __main__ -     Num examples = 7498
09/01/2025 20:13:08 - INFO - __main__ -     Batch size = 8
Evaluating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 938/938 [00:17<00:00, 52.25it/s]
eval result:  6986 0.7982██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋| 936/938 [00:17<00:00, 60.84it/s]
Iteration: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 998/998 [03:48<00:00,  4.37it/s]
09/01/2025 20:17:15 - INFO - __main__ -   Loading features from cached file data/EmbeddingGroups/CROSS-LINGUAL/lug_hau_nya/COMBINED/cached_dev_afro-xlmr-base_164/998 [03:48<00:00,  4.25it/s]
09/01/2025 20:17:15 - INFO - __main__ -   ***** Running evaluation  *****
09/01/2025 20:17:15 - INFO - __main__ -     Num examples = 7498
09/01/2025 20:17:15 - INFO - __main__ -     Batch size = 8
Evaluating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 938/938 [00:16<00:00, 56.19it/s]
eval result:  7984 0.82526█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████ | 932/938 [00:16<00:00, 61.03it/s]
09/01/2025 20:17:34 - INFO - __main__ -   Saving model checkpoint to models/EmbeddingGroups/CROSS-LINGUAL/lug_hau_nya/combined_afroxlmr
Iteration: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 998/998 [03:50<00:00,  4.33it/s]
09/01/2025 20:21:24 - INFO - __main__ -   Loading features from cached file data/EmbeddingGroups/CROSS-LINGUAL/lug_hau_nya/COMBINED/cached_dev_afro-xlmr-base_164/998 [03:50<00:00,  5.87it/s]
09/01/2025 20:21:25 - INFO - __main__ -   ***** Running evaluation  *****
09/01/2025 20:21:25 - INFO - __main__ -     Num examples = 7498
09/01/2025 20:21:25 - INFO - __main__ -     Batch size = 8
Evaluating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 938/938 [00:16<00:00, 57.98it/s]
eval result:  8982 0.82764█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋| 936/938 [00:16<00:00, 35.75it/s]
09/01/2025 20:21:42 - INFO - __main__ -   Saving model checkpoint to models/EmbeddingGroups/CROSS-LINGUAL/lug_hau_nya/combined_afroxlmr
Iteration: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 998/998 [03:49<00:00,  4.34it/s]
09/01/2025 20:25:32 - INFO - __main__ -   Loading features from cached file data/EmbeddingGroups/CROSS-LINGUAL/lug_hau_nya/COMBINED/cached_dev_afro-xlmr-base_164/998 [03:49<00:00,  5.84it/s]
09/01/2025 20:25:32 - INFO - __main__ -   ***** Running evaluation  *****
09/01/2025 20:25:32 - INFO - __main__ -     Num examples = 7498
09/01/2025 20:25:32 - INFO - __main__ -     Batch size = 8
Evaluating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 938/938 [00:19<00:00, 48.93it/s]
eval result:  9980 0.82932██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 938/938 [00:19<00:00, 35.72it/s]
09/01/2025 20:25:53 - INFO - __main__ -   Saving model checkpoint to models/EmbeddingGroups/CROSS-LINGUAL/lug_hau_nya/combined_afroxlmr
Epoch: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [41:21<00:00, 248.11s/it]
09/01/2025 20:25:53 - INFO - __main__ -   Loading features from cached file data/EmbeddingGroups/CROSS-LINGUAL/lug_hau_nya/COMBINED/cached_dev_afro-xlmr-base_164
09/01/2025 20:25:54 - INFO - __main__ -   ***** Running evaluation  *****
09/01/2025 20:25:54 - INFO - __main__ -     Num examples = 7498
09/01/2025 20:25:54 - INFO - __main__ -     Batch size = 8
Evaluating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 938/938 [00:24<00:00, 38.19it/s]
09/01/2025 20:26:19 - INFO - __main__ -    global_step = 9980, average loss = 0.02287458907310406
09/01/2025 20:26:19 - INFO - __main__ -   Saving model checkpoint to models/EmbeddingGroups/CROSS-LINGUAL/lug_hau_nya/combined_afroxlmr
09/01/2025 20:26:20 - INFO - __main__ -   Evaluate the following checkpoints: ['models/EmbeddingGroups/CROSS-LINGUAL/lug_hau_nya/combined_afroxlmr']
09/01/2025 20:26:21 - INFO - __main__ -   Loading features from cached file data/EmbeddingGroups/CROSS-LINGUAL/lug_hau_nya/COMBINED/cached_dev_afro-xlmr-base_164
09/01/2025 20:26:21 - INFO - __main__ -   ***** Running evaluation  *****
09/01/2025 20:26:21 - INFO - __main__ -     Num examples = 7498
09/01/2025 20:26:21 - INFO - __main__ -     Batch size = 8
Evaluating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 938/938 [00:24<00:00, 38.72it/s]
09/01/2025 20:26:46 - INFO - __main__ -   ***** Eval results  *****
09/01/2025 20:26:46 - INFO - __main__ -     f1 = 0.8293208767517067
09/01/2025 20:26:46 - INFO - __main__ -     loss = 0.06213668621320157
09/01/2025 20:26:46 - INFO - __main__ -     precision = 0.8138222849083215
09/01/2025 20:26:46 - INFO - __main__ -     recall = 0.8454212454212454
09/01/2025 20:26:46 - INFO - __main__ -     report =               precision    recall  f1-score   support

        DATE       0.76      0.79      0.77       434
         LOC       0.87      0.90      0.88       688
         ORG       0.70      0.70      0.70       156
         PER       0.86      0.95      0.91        87

   micro avg       0.81      0.85      0.83      1365
   macro avg       0.80      0.84      0.82      1365
weighted avg       0.81      0.85      0.83      1365

09/01/2025 20:26:46 - INFO - __main__ -   Creating features from dataset file at data/EmbeddingGroups/CROSS-LINGUAL/lug_hau_nya/COMBINED/
09/01/2025 20:26:46 - INFO - utils_ner -   Writing example 0 of 7508
09/01/2025 20:26:46 - INFO - utils_ner -   *** Example ***
09/01/2025 20:26:46 - INFO - utils_ner -   guid: test-1
09/01/2025 20:26:46 - INFO - utils_ner -   tokens: <s> ▁Ti imu ▁y ' em iza ano ▁e ya ▁di si turik iti ▁ , ▁e kah ika ▁a ha ▁kamar i rizo ▁om wa ka ▁og uh wa ire ▁ . </s>
09/01/2025 20:26:46 - INFO - utils_ner -   input_ids: 0 2371 15608 113 25 195 7337 3922 28 395 45 172 101605 1890 6 4 28 6577 2959 10 528 21323 14 155946 171 634 161 60 5951 634 2149 6 5 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
09/01/2025 20:26:46 - INFO - utils_ner -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
09/01/2025 20:26:46 - INFO - utils_ner -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
09/01/2025 20:26:46 - INFO - utils_ner -   label_ids: -100 0 -100 0 -100 -100 -100 -100 0 -100 0 -100 -100 -100 0 -100 0 -100 -100 0 -100 0 -100 -100 1 -100 -100 2 -100 -100 -100 0 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100
09/01/2025 20:26:46 - INFO - utils_ner -   *** Example ***
09/01/2025 20:26:46 - INFO - utils_ner -   guid: test-2
09/01/2025 20:26:46 - INFO - utils_ner -   tokens: <s> ▁Sh wen kuru ▁wang ye ▁aka fa ▁aine ▁em yaka ▁kina na ▁na ▁muna na ▁e y ' o buku ru ▁ . </s>
09/01/2025 20:26:46 - INFO - utils_ner -   input_ids: 0 7525 11697 120209 37109 1033 15623 1021 59482 352 122669 24222 76 24 29279 76 28 53 25 31 107798 882 6 5 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
09/01/2025 20:26:46 - INFO - utils_ner -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
09/01/2025 20:26:46 - INFO - utils_ner -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
09/01/2025 20:26:46 - INFO - utils_ner -   label_ids: -100 0 -100 -100 0 -100 0 -100 0 1 -100 2 -100 2 2 -100 0 -100 -100 -100 -100 -100 0 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100
09/01/2025 20:26:46 - INFO - utils_ner -   *** Example ***
09/01/2025 20:26:46 - INFO - utils_ner -   guid: test-3
09/01/2025 20:26:46 - INFO - utils_ner -   tokens: <s> ▁E bi kwa to ▁e biri mu ▁za ▁m izay iro ▁maku mi ▁a tano ▁e by agu zir we ▁kuru ga ▁China ▁bi kaa kii rwa ▁en kumi ▁i biri ▁i kumi ▁na ▁muna na ▁ . </s>
09/01/2025 20:26:46 - INFO - utils_ner -   input_ids: 0 241 964 10521 188 28 35653 561 80 347 83571 8699 62332 266 10 35221 28 1272 26722 26679 1177 14178 208 9098 333 17227 7072 70627 22 87064 17 35653 17 87064 24 29279 76 6 5 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
09/01/2025 20:26:46 - INFO - utils_ner -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
09/01/2025 20:26:46 - INFO - utils_ner -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
09/01/2025 20:26:46 - INFO - utils_ner -   label_ids: -100 0 -100 -100 -100 0 -100 -100 0 0 -100 -100 0 -100 0 -100 0 -100 -100 -100 -100 0 -100 7 0 -100 -100 -100 1 -100 2 -100 2 -100 2 2 -100 0 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100
09/01/2025 20:26:46 - INFO - utils_ner -   *** Example ***
09/01/2025 20:26:46 - INFO - utils_ner -   guid: test-4
09/01/2025 20:26:46 - INFO - utils_ner -   tokens: <s> ▁Aku ruga ▁om u ▁is home ro ▁aine ▁em yaka ▁i kumi ▁na ▁muka aga ▁ . </s>
09/01/2025 20:26:46 - INFO - utils_ner -   input_ids: 0 8158 46892 171 34 83 29552 516 59482 352 122669 17 87064 24 14330 4729 6 5 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
09/01/2025 20:26:46 - INFO - utils_ner -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
09/01/2025 20:26:46 - INFO - utils_ner -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
09/01/2025 20:26:46 - INFO - utils_ner -   label_ids: -100 0 -100 0 -100 0 -100 -100 0 1 -100 2 -100 2 2 -100 0 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100
09/01/2025 20:26:46 - INFO - utils_ner -   *** Example ***
09/01/2025 20:26:46 - INFO - utils_ner -   guid: test-5
09/01/2025 20:26:46 - INFO - utils_ner -   tokens: <s> ▁Ny om web az yo ▁ni b wo ▁ah iki ze ▁em yaka ▁i kumi ▁na ▁muna ana </s>
09/01/2025 20:26:46 - INFO - utils_ner -   input_ids: 0 2949 306 14051 1828 1410 300 275 3613 1263 5898 731 352 122669 17 87064 24 29279 1500 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
09/01/2025 20:26:46 - INFO - utils_ner -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
09/01/2025 20:26:46 - INFO - utils_ner -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
09/01/2025 20:26:46 - INFO - utils_ner -   label_ids: -100 1 -100 -100 -100 -100 0 -100 -100 0 -100 -100 1 -100 2 -100 2 2 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100
09/01/2025 20:26:47 - INFO - __main__ -   Saving features into cached file data/EmbeddingGroups/CROSS-LINGUAL/lug_hau_nya/COMBINED/cached_test_afro-xlmr-base_164
09/01/2025 20:26:48 - INFO - __main__ -   ***** Running evaluation  *****
09/01/2025 20:26:48 - INFO - __main__ -     Num examples = 7508
09/01/2025 20:26:48 - INFO - __main__ -     Batch size = 8
Evaluating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 939/939 [00:24<00:00, 38.19it/s]
09/01/2025 20:27:13 - INFO - __main__ -   ***** Eval results  *****
09/01/2025 20:27:13 - INFO - __main__ -     f1 = 0.8271092669432919
09/01/2025 20:27:13 - INFO - __main__ -     loss = 0.0620111766070474
09/01/2025 20:27:13 - INFO - __main__ -     precision = 0.8169398907103825
09/01/2025 20:27:13 - INFO - __main__ -     recall = 0.8375350140056023
09/01/2025 20:27:13 - INFO - __main__ -     report =               precision    recall  f1-score   support

        DATE       0.75      0.78      0.76       437
         LOC       0.88      0.90      0.89       715
         ORG       0.69      0.70      0.69       162
         PER       0.83      0.89      0.86       114

   micro avg       0.82      0.84      0.83      1428
   macro avg       0.79      0.82      0.80      1428
weighted avg       0.82      0.84      0.83      1428

Starting training with mBERT...
/home/prosper/miniconda3/envs/runyankore-ner/lib/python3.10/site-packages/huggingface_hub/file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
09/01/2025 20:27:16 - INFO - __main__ -   Training/evaluation parameters Namespace(data_dir='data/EmbeddingGroups/CROSS-LINGUAL/lug_hau_nya/COMBINED/', model_type='bert', model_name_or_path='bert-base-multilingual-cased', input_dir=None, output_dir='models/EmbeddingGroups/CROSS-LINGUAL/lug_hau_nya/combined_mbert', test_result_file='test_results.txt', test_prediction_file='test_predictions.txt', labels='', config_name='', tokenizer_name='', cache_dir='', max_seq_length=164, do_train=True, do_finetune=False, do_eval=True, do_predict=True, evaluate_during_training=False, do_lower_case=False, per_gpu_train_batch_size=32, per_gpu_eval_batch_size=8, gradient_accumulation_steps=1, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=10.0, max_steps=-1, warmup_steps=0, logging_steps=500, save_steps=5000, eval_all_checkpoints=False, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=1, local_rank=-1, server_ip='', server_port='', n_gpu=1, device=device(type='cuda'))
09/01/2025 20:27:16 - INFO - __main__ -   Creating features from dataset file at data/EmbeddingGroups/CROSS-LINGUAL/lug_hau_nya/COMBINED/
09/01/2025 20:27:16 - INFO - utils_ner -   Writing example 0 of 31909
09/01/2025 20:27:16 - INFO - utils_ner -   *** Example ***
09/01/2025 20:27:16 - INFO - utils_ner -   guid: train-1
09/01/2025 20:27:16 - INFO - utils_ner -   tokens: [CLS] Ei ##hang ##a ry ##a R ##uras ##ha ni ##ry ##o ry ##aki ##riz ##ey ##o om ##u ku ##gu ##za e ##by ##ama ##gu ##zi om ##uri Af ##iri ##ka ah ##aga ##ti y ' en ##kum ##i ibi ##ri iku ##mi na mu ##shan ##ju n ' en ##kum ##i ibi ##ri iku ##mi na ish ##atu . [SEP]
09/01/2025 20:27:16 - INFO - utils_ner -   input_ids: 101 35278 30222 10113 71259 10113 155 35854 10921 10414 10908 10133 71259 22471 43100 13005 10133 10209 10138 15694 12589 10637 173 11530 15149 12589 11282 10209 13091 71164 19334 10371 69863 19357 10325 193 112 10110 36811 10116 23562 10401 14474 10500 10132 12361 60511 10761 182 112 10110 36811 10116 23562 10401 14474 10500 10132 77076 19003 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
09/01/2025 20:27:16 - INFO - utils_ner -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
09/01/2025 20:27:16 - INFO - utils_ner -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
09/01/2025 20:27:16 - INFO - utils_ner -   label_ids: -100 0 -100 -100 0 -100 7 -100 -100 0 -100 -100 0 -100 -100 -100 -100 0 -100 0 -100 -100 0 -100 -100 -100 -100 0 -100 7 -100 -100 0 -100 -100 1 -100 -100 -100 -100 2 -100 2 -100 2 2 -100 -100 2 -100 -100 -100 -100 2 -100 2 -100 2 2 -100 0 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100
09/01/2025 20:27:16 - INFO - utils_ner -   *** Example ***
09/01/2025 20:27:16 - INFO - utils_ner -   guid: train-2
09/01/2025 20:27:16 - INFO - utils_ner -   tokens: [CLS] Om ##ush ##wi ##ja g ##w ' ensi ##ri gu ##kab ##a gur ##i m ##wing ##i , om ##wak ##a og ##uh ##wei ##re . [SEP]
09/01/2025 20:27:16 - INFO - utils_ner -   input_ids: 101 18864 37026 15926 10320 175 10874 112 67572 10401 75980 44799 10113 58824 10116 181 25649 10116 117 10209 57482 10113 10156 18593 61512 10246 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
09/01/2025 20:27:16 - INFO - utils_ner -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
09/01/2025 20:27:16 - INFO - utils_ner -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
09/01/2025 20:27:16 - INFO - utils_ner -   label_ids: -100 0 -100 -100 -100 0 -100 -100 -100 -100 0 -100 -100 0 -100 0 -100 -100 0 1 -100 -100 2 -100 -100 -100 0 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100
09/01/2025 20:27:16 - INFO - utils_ner -   *** Example ***
09/01/2025 20:27:16 - INFO - utils_ner -   guid: train-3
09/01/2025 20:27:16 - INFO - utils_ner -   tokens: [CLS] Ok ##uja ##gu ##za em ##yak ##a ma ##kum ##i ab ##iri kiri ah ##a kar ##enda . [SEP]
09/01/2025 20:27:16 - INFO - utils_ner -   input_ids: 101 84591 25989 12589 10637 10266 50274 10113 10824 36811 10116 11357 19334 86279 69863 10113 25085 27808 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
09/01/2025 20:27:16 - INFO - utils_ner -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
09/01/2025 20:27:16 - INFO - utils_ner -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
09/01/2025 20:27:16 - INFO - utils_ner -   label_ids: -100 0 -100 -100 -100 1 -100 -100 2 -100 -100 2 -100 0 0 -100 0 -100 0 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100
09/01/2025 20:27:16 - INFO - utils_ner -   *** Example ***
09/01/2025 20:27:16 - INFO - utils_ner -   guid: train-4
09/01/2025 20:27:16 - INFO - utils_ner -   tokens: [CLS] Ak ##eer ##eka ok ##u eki ##ton ##gore ky ##atu ##ngu ##uki ##re om ##u my ##aka iku ##mi e ##hing ##wir ##e . [SEP]
09/01/2025 20:27:16 - INFO - utils_ner -   input_ids: 101 71275 23869 31519 14302 10138 75384 11183 103004 87147 19003 40849 39821 10246 10209 10138 15127 18529 14474 10500 173 30809 86764 10112 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
09/01/2025 20:27:16 - INFO - utils_ner -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
09/01/2025 20:27:16 - INFO - utils_ner -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
09/01/2025 20:27:16 - INFO - utils_ner -   label_ids: -100 0 -100 -100 0 -100 0 -100 -100 0 -100 -100 -100 -100 0 -100 1 -100 2 -100 2 -100 -100 -100 0 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100
09/01/2025 20:27:16 - INFO - utils_ner -   *** Example ***
09/01/2025 20:27:16 - INFO - utils_ner -   guid: train-5
09/01/2025 20:27:16 - INFO - utils_ner -   tokens: [CLS] E ##bih ##em ##bo by ##a vidi ##iyo y ' e ##bye ##sh ##ongo ##ro by ' om ##wak ##a og ##u by ' og ##ye ##zi ##b ##we ##yo . [SEP]
09/01/2025 20:27:16 - INFO - utils_ner -   input_ids: 101 142 108596 10451 11790 10155 10113 71868 86119 193 112 173 87421 13264 95682 10567 10155 112 10209 57482 10113 10156 10138 10155 112 10156 12871 11282 10457 12577 15594 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
09/01/2025 20:27:16 - INFO - utils_ner -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
09/01/2025 20:27:16 - INFO - utils_ner -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
09/01/2025 20:27:16 - INFO - utils_ner -   label_ids: -100 0 -100 -100 -100 0 -100 0 -100 0 -100 -100 -100 -100 -100 -100 1 -100 -100 -100 -100 2 -100 0 -100 -100 -100 -100 -100 -100 -100 0 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100
09/01/2025 20:27:17 - INFO - utils_ner -   Writing example 10000 of 31909
09/01/2025 20:27:19 - INFO - utils_ner -   Writing example 20000 of 31909
09/01/2025 20:27:23 - INFO - utils_ner -   Writing example 30000 of 31909
09/01/2025 20:27:23 - INFO - __main__ -   Saving features into cached file data/EmbeddingGroups/CROSS-LINGUAL/lug_hau_nya/COMBINED/cached_train_bert-base-multilingual-cased_164
/home/prosper/miniconda3/envs/runyankore-ner/lib/python3.10/site-packages/transformers/optimization.py:588: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
09/01/2025 20:27:27 - INFO - __main__ -   ***** Running training *****
09/01/2025 20:27:27 - INFO - __main__ -     Num examples = 31909
09/01/2025 20:27:27 - INFO - __main__ -     Num Epochs = 10
09/01/2025 20:27:27 - INFO - __main__ -     Instantaneous batch size per GPU = 32
09/01/2025 20:27:27 - INFO - __main__ -     Total train batch size (w. parallel, distributed & accumulation) = 32
09/01/2025 20:27:27 - INFO - __main__ -     Gradient Accumulation steps = 1
09/01/2025 20:27:27 - INFO - __main__ -     Total optimization steps = 9980
Epoch:   0%|                                                                                                                                                           | 0/10 [00:00<?, ?it/s/home/prosper/miniconda3/envs/runyankore-ner/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:182: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn(
Iteration: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 998/998 [03:13<00:00,  5.17it/s]
09/01/2025 20:30:40 - INFO - __main__ -   Creating features from dataset file at data/EmbeddingGroups/CROSS-LINGUAL/lug_hau_nya/COMBINED/██████████████████▊| 997/998 [03:12<00:00,  4.89it/s]
09/01/2025 20:30:40 - INFO - utils_ner -   Writing example 0 of 7498
09/01/2025 20:30:40 - INFO - utils_ner -   *** Example ***
09/01/2025 20:30:40 - INFO - utils_ner -   guid: dev-1
09/01/2025 20:30:40 - INFO - utils_ner -   tokens: [CLS] Eis ##hom ##ero ry ##ahan ##dii ##ka ri ##pot ##i ye eri ##zoo ##ba . [SEP]
09/01/2025 20:30:40 - INFO - utils_ner -   input_ids: 101 99119 71784 13739 71259 26019 108310 10371 29956 37604 10116 11023 23152 72713 10537 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
09/01/2025 20:30:40 - INFO - utils_ner -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
09/01/2025 20:30:40 - INFO - utils_ner -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
09/01/2025 20:30:40 - INFO - utils_ner -   label_ids: -100 0 -100 -100 0 -100 -100 -100 0 -100 -100 0 1 -100 -100 0 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100
09/01/2025 20:30:40 - INFO - utils_ner -   *** Example ***
09/01/2025 20:30:40 - INFO - utils_ner -   guid: dev-2
09/01/2025 20:30:40 - INFO - utils_ner -   tokens: [CLS] Ak ##asi ##ng ##wa om ##u kar ##uur ##u om ##wak ##a og ##uh ##wai ##re . [SEP]
09/01/2025 20:30:40 - INFO - utils_ner -   input_ids: 101 71275 15525 10376 11037 10209 10138 25085 24720 10138 10209 57482 10113 10156 18593 69680 10246 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
09/01/2025 20:30:40 - INFO - utils_ner -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
09/01/2025 20:30:40 - INFO - utils_ner -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
09/01/2025 20:30:40 - INFO - utils_ner -   label_ids: -100 0 -100 -100 -100 0 -100 0 -100 -100 1 -100 -100 2 -100 -100 -100 0 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100
09/01/2025 20:30:40 - INFO - utils_ner -   *** Example ***
09/01/2025 20:30:40 - INFO - utils_ner -   guid: dev-3
09/01/2025 20:30:40 - INFO - utils_ner -   tokens: [CLS] Ok ##wo ##mbe ##ka oru ##tin ##do , ni ##k ##wi ##ija ku ##twa ##ra em ##yak ##a es ##hat ##u . [SEP]
09/01/2025 20:30:40 - INFO - utils_ner -   input_ids: 101 84591 16828 35216 10371 88982 15364 10317 117 10414 10174 15926 12823 15694 33494 10288 10266 50274 10113 10196 19180 10138 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
09/01/2025 20:30:40 - INFO - utils_ner -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
09/01/2025 20:30:40 - INFO - utils_ner -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
09/01/2025 20:30:40 - INFO - utils_ner -   label_ids: -100 0 -100 -100 -100 0 -100 -100 0 0 -100 -100 -100 0 -100 -100 1 -100 -100 2 -100 -100 0 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100
09/01/2025 20:30:40 - INFO - utils_ner -   *** Example ***
09/01/2025 20:30:40 - INFO - utils_ner -   guid: dev-4
09/01/2025 20:30:40 - INFO - utils_ner -   tokens: [CLS] Om ##wo ##jo aka ##it ##wa iba ##are eru ##kir ##i or ##wa ##bai ##re or ##wah ##irin ##git ##sir ##e om ##wak ##a og ##wa h ##wai ##re . [SEP]
09/01/2025 20:30:40 - INFO - utils_ner -   input_ids: 101 18864 16828 11039 50825 10486 11037 22791 11591 18098 46994 10116 10345 11037 47727 10246 10345 63784 89080 26264 32749 10112 10209 57482 10113 10156 11037 176 69680 10246 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
09/01/2025 20:30:40 - INFO - utils_ner -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
09/01/2025 20:30:40 - INFO - utils_ner -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
09/01/2025 20:30:40 - INFO - utils_ner -   label_ids: -100 0 -100 -100 0 -100 -100 0 -100 0 -100 -100 0 -100 -100 -100 0 -100 -100 -100 -100 -100 1 -100 -100 2 -100 2 -100 -100 0 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100
09/01/2025 20:30:40 - INFO - utils_ner -   *** Example ***
09/01/2025 20:30:40 - INFO - utils_ner -   guid: dev-5
09/01/2025 20:30:40 - INFO - utils_ner -   tokens: [CLS] Om ##web ##em ##be ##zi w ' ei ##hang ##a aka ##king ##a ama ##kan ##isa ok ##uma ##ra e ##bir ##o ma ##kum ##i mu ##kaa ##ga e ##bin ##di . [SEP]
09/01/2025 20:30:40 - INFO - utils_ner -   input_ids: 101 18864 51943 10451 11044 11282 191 112 10805 30222 10113 50825 15629 10113 28149 10706 19403 14302 16746 10288 173 29241 10133 10824 36811 10116 12361 62266 10483 173 16473 10703 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
09/01/2025 20:30:40 - INFO - utils_ner -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
09/01/2025 20:30:40 - INFO - utils_ner -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
09/01/2025 20:30:40 - INFO - utils_ner -   label_ids: -100 0 -100 -100 -100 -100 0 -100 -100 -100 -100 0 -100 -100 0 -100 -100 0 -100 -100 1 -100 -100 2 -100 -100 2 -100 -100 0 -100 -100 0 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100
09/01/2025 20:30:41 - INFO - __main__ -   Saving features into cached file data/EmbeddingGroups/CROSS-LINGUAL/lug_hau_nya/COMBINED/cached_dev_bert-base-multilingual-cased_164
09/01/2025 20:30:42 - INFO - __main__ -   ***** Running evaluation  *****
09/01/2025 20:30:42 - INFO - __main__ -     Num examples = 7498
09/01/2025 20:30:42 - INFO - __main__ -     Batch size = 8
Evaluating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 938/938 [00:25<00:00, 36.75it/s]
eval result:  998 0.73288██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊| 937/938 [00:25<00:00, 33.04it/s]
09/01/2025 20:31:08 - INFO - __main__ -   Saving model checkpoint to models/EmbeddingGroups/CROSS-LINGUAL/lug_hau_nya/combined_mbert
Iteration: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 998/998 [03:12<00:00,  5.20it/s]
09/01/2025 20:34:20 - INFO - __main__ -   Loading features from cached file data/EmbeddingGroups/CROSS-LINGUAL/lug_hau_nya/COMBINED/cached_dev_bert-base-multilingual-cased_164:00,  4.92it/s]
09/01/2025 20:34:21 - INFO - __main__ -   ***** Running evaluation  *****
09/01/2025 20:34:21 - INFO - __main__ -     Num examples = 7498
09/01/2025 20:34:21 - INFO - __main__ -     Batch size = 8
Evaluating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 938/938 [00:24<00:00, 38.32it/s]
eval result:  1996 0.79221██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 938/938 [00:24<00:00, 34.05it/s]
09/01/2025 20:34:46 - INFO - __main__ -   Saving model checkpoint to models/EmbeddingGroups/CROSS-LINGUAL/lug_hau_nya/combined_mbert
Iteration: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 998/998 [03:12<00:00,  5.18it/s]
09/01/2025 20:37:59 - INFO - __main__ -   Loading features from cached file data/EmbeddingGroups/CROSS-LINGUAL/lug_hau_nya/COMBINED/cached_dev_bert-base-multilingual-cased_164:00,  4.95it/s]
09/01/2025 20:37:59 - INFO - __main__ -   ***** Running evaluation  *****
09/01/2025 20:37:59 - INFO - __main__ -     Num examples = 7498
09/01/2025 20:37:59 - INFO - __main__ -     Batch size = 8
Evaluating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 938/938 [00:24<00:00, 38.27it/s]
eval result:  2994 0.77719█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊| 937/938 [00:24<00:00, 33.75it/s]
Iteration: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 998/998 [03:12<00:00,  5.18it/s]
09/01/2025 20:41:37 - INFO - __main__ -   Loading features from cached file data/EmbeddingGroups/CROSS-LINGUAL/lug_hau_nya/COMBINED/cached_dev_bert-base-multilingual-cased_164:00,  4.92it/s]
09/01/2025 20:41:38 - INFO - __main__ -   ***** Running evaluation  *****
09/01/2025 20:41:38 - INFO - __main__ -     Num examples = 7498
09/01/2025 20:41:38 - INFO - __main__ -     Batch size = 8
Evaluating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 938/938 [00:24<00:00, 37.59it/s]
eval result:  3992 0.80597█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌| 935/938 [00:24<00:00, 32.28it/s]
09/01/2025 20:42:04 - INFO - __main__ -   Saving model checkpoint to models/EmbeddingGroups/CROSS-LINGUAL/lug_hau_nya/combined_mbert
Iteration: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 998/998 [02:59<00:00,  5.56it/s]
09/01/2025 20:45:03 - INFO - __main__ -   Loading features from cached file data/EmbeddingGroups/CROSS-LINGUAL/lug_hau_nya/COMBINED/cached_dev_bert-base-multilingual-cased_164:00,  6.62it/s]
09/01/2025 20:45:04 - INFO - __main__ -   ***** Running evaluation  *****
09/01/2025 20:45:04 - INFO - __main__ -     Num examples = 7498
09/01/2025 20:45:04 - INFO - __main__ -     Batch size = 8
Evaluating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 938/938 [00:14<00:00, 63.64it/s]
eval result:  4990 0.81████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋| 936/938 [00:14<00:00, 61.73it/s]
09/01/2025 20:45:19 - INFO - __main__ -   Saving model checkpoint to models/EmbeddingGroups/CROSS-LINGUAL/lug_hau_nya/combined_mbert
Iteration: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 998/998 [03:11<00:00,  5.22it/s]
09/01/2025 20:48:31 - INFO - __main__ -   Loading features from cached file data/EmbeddingGroups/CROSS-LINGUAL/lug_hau_nya/COMBINED/cached_dev_bert-base-multilingual-cased_164:00,  4.86it/s]
09/01/2025 20:48:31 - INFO - __main__ -   ***** Running evaluation  *****
09/01/2025 20:48:31 - INFO - __main__ -     Num examples = 7498
09/01/2025 20:48:31 - INFO - __main__ -     Batch size = 8
Evaluating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 938/938 [00:26<00:00, 34.92it/s]
eval result:  5988 0.81506█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋| 936/938 [00:26<00:00, 31.64it/s]
09/01/2025 20:48:59 - INFO - __main__ -   Saving model checkpoint to models/EmbeddingGroups/CROSS-LINGUAL/lug_hau_nya/combined_mbert
Iteration: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 998/998 [04:04<00:00,  4.09it/s]
09/01/2025 20:53:03 - INFO - __main__ -   Loading features from cached file data/EmbeddingGroups/CROSS-LINGUAL/lug_hau_nya/COMBINED/cached_dev_bert-base-multilingual-cased_164:00,  3.94it/s]
09/01/2025 20:53:03 - INFO - __main__ -   ***** Running evaluation  *****
09/01/2025 20:53:03 - INFO - __main__ -     Num examples = 7498
09/01/2025 20:53:03 - INFO - __main__ -     Batch size = 8
Evaluating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 938/938 [00:43<00:00, 21.43it/s]
eval result:  6986 0.81033█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋| 936/938 [00:43<00:00, 19.69it/s]
Iteration: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 998/998 [04:52<00:00,  3.42it/s]
09/01/2025 20:58:40 - INFO - __main__ -   Loading features from cached file data/EmbeddingGroups/CROSS-LINGUAL/lug_hau_nya/COMBINED/cached_dev_bert-base-multilingual-cased_164:00,  3.88it/s]
09/01/2025 20:58:40 - INFO - __main__ -   ***** Running evaluation  *****
09/01/2025 20:58:40 - INFO - __main__ -     Num examples = 7498
09/01/2025 20:58:40 - INFO - __main__ -     Batch size = 8
Evaluating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 938/938 [00:43<00:00, 21.58it/s]
eval result:  7984 0.81782█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋| 936/938 [00:43<00:00, 20.52it/s]
09/01/2025 20:59:25 - INFO - __main__ -   Saving model checkpoint to models/EmbeddingGroups/CROSS-LINGUAL/lug_hau_nya/combined_mbert
Iteration: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 998/998 [04:53<00:00,  3.40it/s]
09/01/2025 21:04:18 - INFO - __main__ -   Loading features from cached file data/EmbeddingGroups/CROSS-LINGUAL/lug_hau_nya/COMBINED/cached_dev_bert-base-multilingual-cased_164:00,  4.02it/s]
09/01/2025 21:04:19 - INFO - __main__ -   ***** Running evaluation  *****
09/01/2025 21:04:19 - INFO - __main__ -     Num examples = 7498
09/01/2025 21:04:19 - INFO - __main__ -     Batch size = 8
Evaluating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 938/938 [00:43<00:00, 21.37it/s]
eval result:  8982 0.81436█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊| 937/938 [00:43<00:00, 19.80it/s]
Iteration: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 998/998 [05:10<00:00,  3.22it/s]
09/01/2025 21:10:13 - INFO - __main__ -   Loading features from cached file data/EmbeddingGroups/CROSS-LINGUAL/lug_hau_nya/COMBINED/cached_dev_bert-base-multilingual-cased_164:00,  4.68it/s]
09/01/2025 21:10:14 - INFO - __main__ -   ***** Running evaluation  *****
09/01/2025 21:10:14 - INFO - __main__ -     Num examples = 7498
09/01/2025 21:10:14 - INFO - __main__ -     Batch size = 8
Evaluating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 938/938 [00:32<00:00, 29.04it/s]
eval result:  9980 0.82319█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋| 936/938 [00:32<00:00, 25.12it/s]
09/01/2025 21:10:47 - INFO - __main__ -   Saving model checkpoint to models/EmbeddingGroups/CROSS-LINGUAL/lug_hau_nya/combined_mbert
Epoch: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [43:20<00:00, 260.02s/it]
09/01/2025 21:10:47 - INFO - __main__ -   Loading features from cached file data/EmbeddingGroups/CROSS-LINGUAL/lug_hau_nya/COMBINED/cached_dev_bert-base-multilingual-cased_164
09/01/2025 21:10:48 - INFO - __main__ -   ***** Running evaluation  *****
09/01/2025 21:10:48 - INFO - __main__ -     Num examples = 7498
09/01/2025 21:10:48 - INFO - __main__ -     Batch size = 8
Evaluating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 938/938 [00:40<00:00, 23.39it/s]
09/01/2025 21:11:28 - INFO - __main__ -    global_step = 9980, average loss = 0.02850346170271478
09/01/2025 21:11:28 - INFO - __main__ -   Saving model checkpoint to models/EmbeddingGroups/CROSS-LINGUAL/lug_hau_nya/combined_mbert
09/01/2025 21:11:29 - INFO - __main__ -   Evaluate the following checkpoints: ['models/EmbeddingGroups/CROSS-LINGUAL/lug_hau_nya/combined_mbert']
09/01/2025 21:11:30 - INFO - __main__ -   Loading features from cached file data/EmbeddingGroups/CROSS-LINGUAL/lug_hau_nya/COMBINED/cached_dev_bert-base-multilingual-cased_164
09/01/2025 21:11:30 - INFO - __main__ -   ***** Running evaluation  *****
09/01/2025 21:11:30 - INFO - __main__ -     Num examples = 7498
09/01/2025 21:11:30 - INFO - __main__ -     Batch size = 8
Evaluating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 938/938 [00:42<00:00, 21.90it/s]
09/01/2025 21:12:13 - INFO - __main__ -   ***** Eval results  *****
09/01/2025 21:12:13 - INFO - __main__ -     f1 = 0.8231904933381348
09/01/2025 21:12:13 - INFO - __main__ -     loss = 0.06900400267674114
09/01/2025 21:12:13 - INFO - __main__ -     precision = 0.8094900849858357
09/01/2025 21:12:13 - INFO - __main__ -     recall = 0.8373626373626374
09/01/2025 21:12:13 - INFO - __main__ -     report =               precision    recall  f1-score   support

        DATE       0.76      0.79      0.78       434
         LOC       0.86      0.88      0.87       688
         ORG       0.75      0.71      0.73       156
         PER       0.79      0.95      0.86        87

   micro avg       0.81      0.84      0.82      1365
   macro avg       0.79      0.83      0.81      1365
weighted avg       0.81      0.84      0.82      1365

09/01/2025 21:12:14 - INFO - __main__ -   Creating features from dataset file at data/EmbeddingGroups/CROSS-LINGUAL/lug_hau_nya/COMBINED/
09/01/2025 21:12:14 - INFO - utils_ner -   Writing example 0 of 7508
09/01/2025 21:12:14 - INFO - utils_ner -   *** Example ***
09/01/2025 21:12:14 - INFO - utils_ner -   guid: test-1
09/01/2025 21:12:14 - INFO - utils_ner -   tokens: [CLS] Ti ##imu y ' em ##iza ##ano e ##ya dis ##itur ##iki ##ti , ek ##ahi ##ka ah ##a kama ##rir ##izo om ##wak ##a og ##uh ##wai ##re . [SEP]
09/01/2025 21:12:14 - INFO - utils_ner -   input_ids: 101 29033 43197 193 112 10266 24213 12301 173 10679 27920 96065 20897 10325 117 16334 100962 10371 69863 10113 23559 23897 58452 10209 57482 10113 10156 18593 69680 10246 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
09/01/2025 21:12:14 - INFO - utils_ner -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
09/01/2025 21:12:14 - INFO - utils_ner -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
09/01/2025 21:12:14 - INFO - utils_ner -   label_ids: -100 0 -100 0 -100 -100 -100 -100 0 -100 0 -100 -100 -100 0 0 -100 -100 0 -100 0 -100 -100 1 -100 -100 2 -100 -100 -100 0 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100
09/01/2025 21:12:14 - INFO - utils_ner -   *** Example ***
09/01/2025 21:12:14 - INFO - utils_ner -   guid: test-2
09/01/2025 21:12:14 - INFO - utils_ner -   tokens: [CLS] S ##h ##wen ##kur ##u wa ##ng ##ye aka ##fa ai ##ne em ##yak ##a kin ##ana na mun ##ana e ##y ' obu ##kur ##u . [SEP]
09/01/2025 21:12:14 - INFO - utils_ner -   input_ids: 101 156 10237 19584 24260 10138 11471 10376 12871 50825 13369 11346 10238 10266 50274 10113 37403 11631 10132 101833 11631 173 10157 112 52968 24260 10138 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
09/01/2025 21:12:14 - INFO - utils_ner -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
09/01/2025 21:12:14 - INFO - utils_ner -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
09/01/2025 21:12:14 - INFO - utils_ner -   label_ids: -100 0 -100 -100 -100 -100 0 -100 -100 0 -100 0 -100 1 -100 -100 2 -100 2 2 -100 0 -100 -100 -100 -100 -100 0 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100
09/01/2025 21:12:14 - INFO - utils_ner -   *** Example ***
09/01/2025 21:12:14 - INFO - utils_ner -   guid: test-3
09/01/2025 21:12:14 - INFO - utils_ner -   tokens: [CLS] E ##bik ##wat ##o e ##bir ##imu za miz ##ay ##iro ma ##kum ##i ata ##no e ##by ##agu ##zir ##we kuru ##ga China bi ##kaa ##kii ##r ##wa en ##kum ##i ibi ##ri iku ##mi na mun ##ana . [SEP]
09/01/2025 21:12:14 - INFO - utils_ner -   input_ids: 101 142 59155 33670 10133 173 29241 43197 10339 60919 13998 14213 10824 36811 10116 21695 10343 173 11530 47540 84333 12577 48350 10483 11593 11342 62266 70149 10129 11037 10110 36811 10116 23562 10401 14474 10500 10132 101833 11631 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
09/01/2025 21:12:14 - INFO - utils_ner -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
09/01/2025 21:12:14 - INFO - utils_ner -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
09/01/2025 21:12:14 - INFO - utils_ner -   label_ids: -100 0 -100 -100 -100 0 -100 -100 0 0 -100 -100 0 -100 -100 0 -100 0 -100 -100 -100 -100 0 -100 7 0 -100 -100 -100 -100 1 -100 -100 2 -100 2 -100 2 2 -100 0 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100
09/01/2025 21:12:14 - INFO - utils_ner -   *** Example ***
09/01/2025 21:12:14 - INFO - utils_ner -   guid: test-4
09/01/2025 21:12:14 - INFO - utils_ner -   tokens: [CLS] Aku ##ruga om ##u ish ##ome ##ro ai ##ne em ##yak ##a iku ##mi na mu ##kaa ##ga . [SEP]
09/01/2025 21:12:14 - INFO - utils_ner -   input_ids: 101 59157 92307 10209 10138 77076 22451 10567 11346 10238 10266 50274 10113 14474 10500 10132 12361 62266 10483 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
09/01/2025 21:12:14 - INFO - utils_ner -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
09/01/2025 21:12:14 - INFO - utils_ner -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
09/01/2025 21:12:14 - INFO - utils_ner -   label_ids: -100 0 -100 0 -100 0 -100 -100 0 -100 1 -100 -100 2 -100 2 2 -100 -100 0 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100
09/01/2025 21:12:14 - INFO - utils_ner -   *** Example ***
09/01/2025 21:12:14 - INFO - utils_ner -   guid: test-5
09/01/2025 21:12:14 - INFO - utils_ner -   tokens: [CLS] Ny ##om ##web ##az ##yo ni ##b ##wo ah ##iki ##ze em ##yak ##a iku ##mi na mun ##aan ##a [SEP]
09/01/2025 21:12:14 - INFO - utils_ner -   input_ids: 101 11459 10692 51943 16724 15594 10414 10457 16828 69863 20897 10870 10266 50274 10113 14474 10500 10132 101833 12521 10113 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
09/01/2025 21:12:14 - INFO - utils_ner -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
09/01/2025 21:12:14 - INFO - utils_ner -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
09/01/2025 21:12:14 - INFO - utils_ner -   label_ids: -100 1 -100 -100 -100 -100 0 -100 -100 0 -100 -100 1 -100 -100 2 -100 2 2 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100
09/01/2025 21:12:15 - INFO - __main__ -   Saving features into cached file data/EmbeddingGroups/CROSS-LINGUAL/lug_hau_nya/COMBINED/cached_test_bert-base-multilingual-cased_164
09/01/2025 21:12:16 - INFO - __main__ -   ***** Running evaluation  *****
09/01/2025 21:12:16 - INFO - __main__ -     Num examples = 7508
09/01/2025 21:12:16 - INFO - __main__ -     Batch size = 8
Evaluating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 939/939 [00:43<00:00, 21.73it/s]
09/01/2025 21:13:00 - INFO - __main__ -   ***** Eval results  *****
09/01/2025 21:13:00 - INFO - __main__ -     f1 = 0.8086568189625557
09/01/2025 21:13:00 - INFO - __main__ -     loss = 0.07562883272060218
09/01/2025 21:13:00 - INFO - __main__ -     precision = 0.7936614969656103
09/01/2025 21:13:00 - INFO - __main__ -     recall = 0.8242296918767507
09/01/2025 21:13:00 - INFO - __main__ -     report =               precision    recall  f1-score   support

        DATE       0.72      0.76      0.74       437
         LOC       0.86      0.88      0.87       715
         ORG       0.73      0.73      0.73       162
         PER       0.76      0.85      0.80       114

   micro avg       0.79      0.82      0.81      1428
   macro avg       0.77      0.80      0.79      1428
weighted avg       0.79      0.82      0.81      1428

Starting training with XLM-R...
/home/prosper/miniconda3/envs/runyankore-ner/lib/python3.10/site-packages/huggingface_hub/file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
09/01/2025 21:13:03 - INFO - __main__ -   Training/evaluation parameters Namespace(data_dir='data/EmbeddingGroups/CROSS-LINGUAL/lug_hau_nya/COMBINED/', model_type='xlmroberta', model_name_or_path='xlm-roberta-base', input_dir=None, output_dir='models/EmbeddingGroups/CROSS-LINGUAL/lug_hau_nya/combined_xlmr', test_result_file='test_results.txt', test_prediction_file='test_predictions.txt', labels='', config_name='', tokenizer_name='', cache_dir='', max_seq_length=164, do_train=True, do_finetune=False, do_eval=True, do_predict=True, evaluate_during_training=False, do_lower_case=False, per_gpu_train_batch_size=32, per_gpu_eval_batch_size=8, gradient_accumulation_steps=1, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=10.0, max_steps=-1, warmup_steps=0, logging_steps=500, save_steps=5000, eval_all_checkpoints=False, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=1, local_rank=-1, server_ip='', server_port='', n_gpu=1, device=device(type='cuda'))
09/01/2025 21:13:03 - INFO - __main__ -   Creating features from dataset file at data/EmbeddingGroups/CROSS-LINGUAL/lug_hau_nya/COMBINED/
09/01/2025 21:13:04 - INFO - utils_ner -   Writing example 0 of 31909
09/01/2025 21:13:04 - INFO - utils_ner -   *** Example ***
09/01/2025 21:13:04 - INFO - utils_ner -   guid: train-1
09/01/2025 21:13:04 - INFO - utils_ner -   tokens: <s> ▁Ei hanga ▁ry a ▁Ru rash a ▁ni ry o ▁ry a kiri ze yo ▁om u ▁ku gu za ▁e by ama guzi ▁om uri ▁A fi rika ▁a haga ti ▁y ' en kumi ▁i biri ▁i kumi ▁na ▁mush anju ▁n ' en kumi ▁i biri ▁i kumi ▁na ▁ish atu ▁ . </s>
09/01/2025 21:13:04 - INFO - utils_ner -   input_ids: 0 4565 58146 5535 11 4518 41535 11 300 1294 31 5535 11 27531 731 1410 171 34 228 1234 596 28 1272 2887 79255 171 1162 62 1029 14265 10 94562 118 113 25 33 87064 17 35653 17 87064 24 79755 73604 653 25 33 87064 17 35653 17 87064 24 12277 7945 6 5 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
09/01/2025 21:13:04 - INFO - utils_ner -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
09/01/2025 21:13:04 - INFO - utils_ner -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
09/01/2025 21:13:04 - INFO - utils_ner -   label_ids: -100 0 -100 0 -100 7 -100 -100 0 -100 -100 0 -100 -100 -100 -100 0 -100 0 -100 -100 0 -100 -100 -100 0 -100 7 -100 -100 0 -100 -100 1 -100 -100 -100 2 -100 2 -100 2 2 -100 2 -100 -100 -100 2 -100 2 -100 2 2 -100 0 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100
09/01/2025 21:13:04 - INFO - utils_ner -   *** Example ***
09/01/2025 21:13:04 - INFO - utils_ner -   guid: train-2
09/01/2025 21:13:04 - INFO - utils_ner -   tokens: <s> ▁Om ush wij a ▁gw ' en siri ▁gu ka ba ▁ guri ▁mw ingi ▁ , ▁om wa ka ▁og u hwe ire ▁ . </s>
09/01/2025 21:13:04 - INFO - utils_ner -   input_ids: 0 2383 33768 32674 11 13303 25 33 83468 2497 161 402 6 69140 43879 22242 6 4 171 634 161 60 34 67116 2149 6 5 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
09/01/2025 21:13:04 - INFO - utils_ner -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
09/01/2025 21:13:04 - INFO - utils_ner -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
09/01/2025 21:13:04 - INFO - utils_ner -   label_ids: -100 0 -100 -100 -100 0 -100 -100 -100 0 -100 -100 0 -100 0 -100 0 -100 1 -100 -100 2 -100 -100 -100 0 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100
09/01/2025 21:13:04 - INFO - utils_ner -   *** Example ***
09/01/2025 21:13:04 - INFO - utils_ner -   guid: train-3
09/01/2025 21:13:04 - INFO - utils_ner -   tokens: <s> ▁Oku jag uza ▁em yaka ▁maku mi ▁a biri ▁kiri ▁a ha ▁kar enda ▁ . </s>
09/01/2025 21:13:04 - INFO - utils_ner -   input_ids: 0 81370 100462 23332 352 122669 62332 266 10 35653 30420 10 528 1185 7074 6 5 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
09/01/2025 21:13:04 - INFO - utils_ner -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
09/01/2025 21:13:04 - INFO - utils_ner -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
09/01/2025 21:13:04 - INFO - utils_ner -   label_ids: -100 0 -100 -100 1 -100 2 -100 2 -100 0 0 -100 0 -100 0 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100
09/01/2025 21:13:04 - INFO - utils_ner -   *** Example ***
09/01/2025 21:13:04 - INFO - utils_ner -   guid: train-4
09/01/2025 21:13:04 - INFO - utils_ner -   tokens: <s> ▁A keer eka ▁oku ▁e ki tong ore ▁kya tung u uki re ▁om u ▁my aka ▁i kumi ▁e hing wir e ▁ . </s>
09/01/2025 21:13:04 - INFO - utils_ner -   input_ids: 0 62 49776 26228 14770 28 301 18176 4524 30427 8587 34 38662 107 171 34 759 9227 17 87064 28 33059 17084 13 6 5 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
09/01/2025 21:13:04 - INFO - utils_ner -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
09/01/2025 21:13:04 - INFO - utils_ner -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
09/01/2025 21:13:04 - INFO - utils_ner -   label_ids: -100 0 -100 -100 0 0 -100 -100 -100 0 -100 -100 -100 -100 0 -100 1 -100 2 -100 2 -100 -100 -100 0 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100
09/01/2025 21:13:04 - INFO - utils_ner -   *** Example ***
09/01/2025 21:13:04 - INFO - utils_ner -   guid: train-5
09/01/2025 21:13:04 - INFO - utils_ner -   tokens: <s> ▁E bi hem bo ▁by a ▁vidi iyo ▁y ' e by es hong oro ▁by ' om wa ka ▁og u ▁by ' og ye zib we yo ▁ . </s>
09/01/2025 21:13:04 - INFO - utils_ner -   input_ids: 0 241 964 7701 837 390 11 16631 10734 113 25 13 1272 90 30434 12393 390 25 306 634 161 60 34 390 25 1663 1033 120818 1177 1410 6 5 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
09/01/2025 21:13:04 - INFO - utils_ner -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
09/01/2025 21:13:04 - INFO - utils_ner -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
09/01/2025 21:13:04 - INFO - utils_ner -   label_ids: -100 0 -100 -100 -100 0 -100 0 -100 0 -100 -100 -100 -100 -100 -100 1 -100 -100 -100 -100 2 -100 0 -100 -100 -100 -100 -100 -100 0 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100
09/01/2025 21:13:05 - INFO - utils_ner -   Writing example 10000 of 31909
09/01/2025 21:13:07 - INFO - utils_ner -   Writing example 20000 of 31909
09/01/2025 21:13:10 - INFO - utils_ner -   Writing example 30000 of 31909
09/01/2025 21:13:11 - INFO - __main__ -   Saving features into cached file data/EmbeddingGroups/CROSS-LINGUAL/lug_hau_nya/COMBINED/cached_train_xlm-roberta-base_164
/home/prosper/miniconda3/envs/runyankore-ner/lib/python3.10/site-packages/transformers/optimization.py:588: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
09/01/2025 21:13:15 - INFO - __main__ -   ***** Running training *****
09/01/2025 21:13:15 - INFO - __main__ -     Num examples = 31909
09/01/2025 21:13:15 - INFO - __main__ -     Num Epochs = 10
09/01/2025 21:13:15 - INFO - __main__ -     Instantaneous batch size per GPU = 32
09/01/2025 21:13:15 - INFO - __main__ -     Total train batch size (w. parallel, distributed & accumulation) = 32
09/01/2025 21:13:15 - INFO - __main__ -     Gradient Accumulation steps = 1
09/01/2025 21:13:15 - INFO - __main__ -     Total optimization steps = 9980
Epoch:   0%|                                                                                                                                                           | 0/10 [00:00<?, ?it/s/home/prosper/miniconda3/envs/runyankore-ner/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:182: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn(
Iteration:   0%|▏                                                                                                                                             | 1/998 [00:00<11:06,  1.50it/s]
Epoch:   0%|                                                                                                                                                           | 0/10 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/home/prosper/scratch/prosper/runyankoreNER/code/train_ner.py", line 686, in <module>
    main()
  File "/home/prosper/scratch/prosper/runyankoreNER/code/train_ner.py", line 589, in main
    global_step, tr_loss, max_f1, model_saved = train(args, train_dataset, model, tokenizer, labels, pad_token_label_id)
  File "/home/prosper/scratch/prosper/runyankoreNER/code/train_ner.py", line 168, in train
    outputs = model(**inputs)
  File "/home/prosper/miniconda3/envs/runyankore-ner/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/prosper/miniconda3/envs/runyankore-ner/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/prosper/miniconda3/envs/runyankore-ner/lib/python3.10/site-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py", line 1401, in forward
    outputs = self.roberta(
  File "/home/prosper/miniconda3/envs/runyankore-ner/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/prosper/miniconda3/envs/runyankore-ner/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/prosper/miniconda3/envs/runyankore-ner/lib/python3.10/site-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py", line 834, in forward
    encoder_outputs = self.encoder(
  File "/home/prosper/miniconda3/envs/runyankore-ner/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/prosper/miniconda3/envs/runyankore-ner/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/prosper/miniconda3/envs/runyankore-ner/lib/python3.10/site-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py", line 522, in forward
    layer_outputs = layer_module(
  File "/home/prosper/miniconda3/envs/runyankore-ner/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/prosper/miniconda3/envs/runyankore-ner/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/prosper/miniconda3/envs/runyankore-ner/lib/python3.10/site-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py", line 411, in forward
    self_attention_outputs = self.attention(
  File "/home/prosper/miniconda3/envs/runyankore-ner/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/prosper/miniconda3/envs/runyankore-ner/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/prosper/miniconda3/envs/runyankore-ner/lib/python3.10/site-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py", line 338, in forward
    self_outputs = self.self(
  File "/home/prosper/miniconda3/envs/runyankore-ner/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/prosper/miniconda3/envs/runyankore-ner/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/prosper/miniconda3/envs/runyankore-ner/lib/python3.10/site-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py", line 211, in forward
    value_layer = self.transpose_for_scores(self.value(hidden_states))
  File "/home/prosper/miniconda3/envs/runyankore-ner/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/prosper/miniconda3/envs/runyankore-ner/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/prosper/miniconda3/envs/runyankore-ner/lib/python3.10/site-packages/torch/nn/modules/linear.py", line 125, in forward
    return F.linear(input, self.weight, self.bias)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 23.43 GiB of which 11.44 MiB is free. Process 382377 has 8.78 GiB memory in use. Process 382520 has 8.09 GiB memory in use. Including non-PyTorch memory, this process has 6.53 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 175.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
All training jobs completed.
(runyankore-ner) prosper@badkamer:~/scratch/prosper/runyankoreNER$ nvidia-smi
Mon Sep  1 21:16:40 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 550.163.01             Driver Version: 550.163.01     CUDA Version: 12.4     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA GeForce RTX 4090        Off |   00000000:01:00.0 Off |                  Off |
| 85%   70C    P2            402W /  450W |   17297MiB /  24564MiB |    100%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   1  NVIDIA GeForce RTX 4090        Off |   00000000:05:00.0 Off |                  Off |
| 75%   65C    P2            396W /  450W |    6240MiB /  24564MiB |     99%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|    0   N/A  N/A    382377      C   python3                                      8994MiB |
|    0   N/A  N/A    382520      C   python3                                      8288MiB |
|    1   N/A  N/A    383046      C   python3                                      6230MiB |
+-----------------------------------------------------------------------------------------+
(runyankore-ner) prosper@badkamer:~/scratch/prosper/runyankoreNER$ nvidia-smi
Mon Sep  1 22:01:28 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 550.163.01             Driver Version: 550.163.01     CUDA Version: 12.4     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA GeForce RTX 4090        Off |   00000000:01:00.0 Off |                  Off |
| 81%   68C    P2            424W /  450W |    6240MiB /  24564MiB |     82%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   1  NVIDIA GeForce RTX 4090        Off |   00000000:05:00.0 Off |                  Off |
|  0%   31C    P8             16W /  450W |       2MiB /  24564MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|    0   N/A  N/A    383556      C   python3                                      6230MiB |
+-----------------------------------------------------------------------------------------+
(runyankore-ner) prosper@badkamer:~/scratch/prosper/runyankoreNER$ ./rq2_train_scripts/Embeddings/CROSS-LINGUAL-TRAINING/lug_hau_nya/train_all_PLMs_combined_dataset.sh
Starting training with AfroXLMR...
/home/prosper/miniconda3/envs/runyankore-ner/lib/python3.10/site-packages/huggingface_hub/file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
09/01/2025 22:05:08 - INFO - __main__ -   Training/evaluation parameters Namespace(data_dir='data/EmbeddingGroups/CROSS-LINGUAL/lug_hau_nya/COMBINED/', model_type='xlmroberta', model_name_or_path='Davlan/afro-xlmr-base', input_dir=None, output_dir='models/EmbeddingGroups/CROSS-LINGUAL/lug_hau_nya/combined_afroxlmr', test_result_file='test_results.txt', test_prediction_file='test_predictions.txt', labels='', config_name='', tokenizer_name='', cache_dir='', max_seq_length=164, do_train=True, do_finetune=False, do_eval=True, do_predict=True, evaluate_during_training=False, do_lower_case=False, per_gpu_train_batch_size=32, per_gpu_eval_batch_size=8, gradient_accumulation_steps=1, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=10.0, max_steps=-1, warmup_steps=0, logging_steps=500, save_steps=5000, eval_all_checkpoints=False, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=1, local_rank=-1, server_ip='', server_port='', n_gpu=1, device=device(type='cuda'))
09/01/2025 22:05:08 - INFO - __main__ -   Loading features from cached file data/EmbeddingGroups/CROSS-LINGUAL/lug_hau_nya/COMBINED/cached_train_afro-xlmr-base_164
/home/prosper/miniconda3/envs/runyankore-ner/lib/python3.10/site-packages/transformers/optimization.py:588: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
09/01/2025 22:05:10 - INFO - __main__ -   ***** Running training *****
09/01/2025 22:05:10 - INFO - __main__ -     Num examples = 31909
09/01/2025 22:05:10 - INFO - __main__ -     Num Epochs = 10
09/01/2025 22:05:10 - INFO - __main__ -     Instantaneous batch size per GPU = 32
09/01/2025 22:05:10 - INFO - __main__ -     Total train batch size (w. parallel, distributed & accumulation) = 32
09/01/2025 22:05:10 - INFO - __main__ -     Gradient Accumulation steps = 1
09/01/2025 22:05:10 - INFO - __main__ -     Total optimization steps = 9980
Epoch:   0%|                                                                                                                                                           | 0/10 [00:00<?, ?it/s/home/prosper/miniconda3/envs/runyankore-ner/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:182: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn(
Iteration: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 998/998 [03:46<00:00,  4.41it/s]
09/01/2025 22:08:56 - INFO - __main__ -   Loading features from cached file data/EmbeddingGroups/CROSS-LINGUAL/lug_hau_nya/COMBINED/cached_dev_afro-xlmr-base_164/998 [03:45<00:00,  4.20it/s]
09/01/2025 22:08:57 - INFO - __main__ -   ***** Running evaluation  *****
09/01/2025 22:08:57 - INFO - __main__ -     Num examples = 7498
09/01/2025 22:08:57 - INFO - __main__ -     Batch size = 8
Evaluating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 938/938 [00:25<00:00, 36.94it/s]
eval result:  998 0.75833███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 938/938 [00:25<00:00, 32.96it/s]
09/01/2025 22:09:24 - INFO - __main__ -   Saving model checkpoint to models/EmbeddingGroups/CROSS-LINGUAL/lug_hau_nya/combined_afroxlmr
Iteration: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 998/998 [03:46<00:00,  4.40it/s]
09/01/2025 22:13:10 - INFO - __main__ -   Loading features from cached file data/EmbeddingGroups/CROSS-LINGUAL/lug_hau_nya/COMBINED/cached_dev_afro-xlmr-base_164/998 [03:46<00:00,  5.04it/s]
09/01/2025 22:13:11 - INFO - __main__ -   ***** Running evaluation  *****
09/01/2025 22:13:11 - INFO - __main__ -     Num examples = 7498
09/01/2025 22:13:11 - INFO - __main__ -     Batch size = 8
Evaluating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 938/938 [00:25<00:00, 37.14it/s]
eval result:  1996 0.79419█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋| 936/938 [00:25<00:00, 32.83it/s]
09/01/2025 22:13:38 - INFO - __main__ -   Saving model checkpoint to models/EmbeddingGroups/CROSS-LINGUAL/lug_hau_nya/combined_afroxlmr
Iteration: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 998/998 [03:52<00:00,  4.30it/s]
09/01/2025 22:17:30 - INFO - __main__ -   Loading features from cached file data/EmbeddingGroups/CROSS-LINGUAL/lug_hau_nya/COMBINED/cached_dev_afro-xlmr-base_164/998 [03:52<00:00,  5.58it/s]
09/01/2025 22:17:30 - INFO - __main__ -   ***** Running evaluation  *****
09/01/2025 22:17:30 - INFO - __main__ -     Num examples = 7498
09/01/2025 22:17:30 - INFO - __main__ -     Batch size = 8
Evaluating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 938/938 [00:22<00:00, 42.03it/s]
eval result:  2994 0.79505██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 938/938 [00:22<00:00, 34.27it/s]
09/01/2025 22:17:54 - INFO - __main__ -   Saving model checkpoint to models/EmbeddingGroups/CROSS-LINGUAL/lug_hau_nya/combined_afroxlmr
Iteration: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 998/998 [03:57<00:00,  4.21it/s]
09/01/2025 22:21:51 - INFO - __main__ -   Loading features from cached file data/EmbeddingGroups/CROSS-LINGUAL/lug_hau_nya/COMBINED/cached_dev_afro-xlmr-base_164/998 [03:57<00:00,  5.56it/s]
09/01/2025 22:21:52 - INFO - __main__ -   ***** Running evaluation  *****
09/01/2025 22:21:52 - INFO - __main__ -     Num examples = 7498
09/01/2025 22:21:52 - INFO - __main__ -     Batch size = 8
Evaluating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 938/938 [00:15<00:00, 60.02it/s]
eval result:  3992 0.78535█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎| 933/938 [00:15<00:00, 49.40it/s]
Iteration: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 998/998 [03:58<00:00,  4.19it/s]
09/01/2025 22:26:06 - INFO - __main__ -   Loading features from cached file data/EmbeddingGroups/CROSS-LINGUAL/lug_hau_nya/COMBINED/cached_dev_afro-xlmr-base_164/998 [03:58<00:00,  4.18it/s]
09/01/2025 22:26:06 - INFO - __main__ -   ***** Running evaluation  *****
09/01/2025 22:26:06 - INFO - __main__ -     Num examples = 7498
09/01/2025 22:26:06 - INFO - __main__ -     Batch size = 8
Evaluating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 938/938 [00:21<00:00, 43.61it/s]
eval result:  4990 0.80949█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌| 935/938 [00:21<00:00, 60.46it/s]
09/01/2025 22:26:30 - INFO - __main__ -   Saving model checkpoint to models/EmbeddingGroups/CROSS-LINGUAL/lug_hau_nya/combined_afroxlmr
Iteration: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 998/998 [03:49<00:00,  4.35it/s]
09/01/2025 22:30:19 - INFO - __main__ -   Loading features from cached file data/EmbeddingGroups/CROSS-LINGUAL/lug_hau_nya/COMBINED/cached_dev_afro-xlmr-base_164/998 [03:49<00:00,  4.24it/s]
09/01/2025 22:30:19 - INFO - __main__ -   ***** Running evaluation  *****
09/01/2025 22:30:19 - INFO - __main__ -     Num examples = 7498
09/01/2025 22:30:19 - INFO - __main__ -     Batch size = 8
Evaluating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 938/938 [00:25<00:00, 37.15it/s]
eval result:  5988 0.81747█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊| 937/938 [00:25<00:00, 32.92it/s]
09/01/2025 22:30:46 - INFO - __main__ -   Saving model checkpoint to models/EmbeddingGroups/CROSS-LINGUAL/lug_hau_nya/combined_afroxlmr
Iteration: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 998/998 [03:46<00:00,  4.40it/s]
09/01/2025 22:34:33 - INFO - __main__ -   Loading features from cached file data/EmbeddingGroups/CROSS-LINGUAL/lug_hau_nya/COMBINED/cached_dev_afro-xlmr-base_164/998 [03:46<00:00,  5.04it/s]
09/01/2025 22:34:34 - INFO - __main__ -   ***** Running evaluation  *****
09/01/2025 22:34:34 - INFO - __main__ -     Num examples = 7498
09/01/2025 22:34:34 - INFO - __main__ -     Batch size = 8
Evaluating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 938/938 [00:25<00:00, 37.25it/s]
eval result:  6986 0.7982██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋| 936/938 [00:25<00:00, 33.74it/s]
Iteration: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 998/998 [03:48<00:00,  4.38it/s]
09/01/2025 22:38:47 - INFO - __main__ -   Loading features from cached file data/EmbeddingGroups/CROSS-LINGUAL/lug_hau_nya/COMBINED/cached_dev_afro-xlmr-base_164/998 [03:48<00:00,  5.07it/s]
09/01/2025 22:38:48 - INFO - __main__ -   ***** Running evaluation  *****
09/01/2025 22:38:48 - INFO - __main__ -     Num examples = 7498
09/01/2025 22:38:48 - INFO - __main__ -     Batch size = 8
Evaluating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 938/938 [00:25<00:00, 37.13it/s]
eval result:  7984 0.82526█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊| 937/938 [00:25<00:00, 32.27it/s]
09/01/2025 22:39:15 - INFO - __main__ -   Saving model checkpoint to models/EmbeddingGroups/CROSS-LINGUAL/lug_hau_nya/combined_afroxlmr
Iteration: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 998/998 [03:46<00:00,  4.40it/s]
09/01/2025 22:43:02 - INFO - __main__ -   Loading features from cached file data/EmbeddingGroups/CROSS-LINGUAL/lug_hau_nya/COMBINED/cached_dev_afro-xlmr-base_164/998 [03:46<00:00,  5.06it/s]
09/01/2025 22:43:02 - INFO - __main__ -   ***** Running evaluation  *****
09/01/2025 22:43:02 - INFO - __main__ -     Num examples = 7498
09/01/2025 22:43:02 - INFO - __main__ -     Batch size = 8
Evaluating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 938/938 [00:25<00:00, 37.11it/s]
eval result:  8982 0.82764█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊| 937/938 [00:25<00:00, 32.71it/s]
09/01/2025 22:43:29 - INFO - __main__ -   Saving model checkpoint to models/EmbeddingGroups/CROSS-LINGUAL/lug_hau_nya/combined_afroxlmr
Iteration: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 998/998 [03:13<00:00,  5.15it/s]
09/01/2025 22:46:43 - INFO - __main__ -   Loading features from cached file data/EmbeddingGroups/CROSS-LINGUAL/lug_hau_nya/COMBINED/cached_dev_afro-xlmr-base_164/998 [03:13<00:00,  6.06it/s]
09/01/2025 22:46:43 - INFO - __main__ -   ***** Running evaluation  *****
09/01/2025 22:46:43 - INFO - __main__ -     Num examples = 7498
09/01/2025 22:46:43 - INFO - __main__ -     Batch size = 8
Evaluating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 938/938 [00:10<00:00, 91.17it/s]
eval result:  9980 0.82932█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊| 937/938 [00:10<00:00, 67.41it/s]
09/01/2025 22:46:55 - INFO - __main__ -   Saving model checkpoint to models/EmbeddingGroups/CROSS-LINGUAL/lug_hau_nya/combined_afroxlmr
Epoch: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [41:44<00:00, 250.49s/it]
09/01/2025 22:46:55 - INFO - __main__ -   Loading features from cached file data/EmbeddingGroups/CROSS-LINGUAL/lug_hau_nya/COMBINED/cached_dev_afro-xlmr-base_164
09/01/2025 22:46:55 - INFO - __main__ -   ***** Running evaluation  *****
09/01/2025 22:46:55 - INFO - __main__ -     Num examples = 7498
09/01/2025 22:46:55 - INFO - __main__ -     Batch size = 8
Evaluating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 938/938 [00:09<00:00, 94.61it/s]
09/01/2025 22:47:06 - INFO - __main__ -    global_step = 9980, average loss = 0.02287458907310406
09/01/2025 22:47:06 - INFO - __main__ -   Saving model checkpoint to models/EmbeddingGroups/CROSS-LINGUAL/lug_hau_nya/combined_afroxlmr
09/01/2025 22:47:07 - INFO - __main__ -   Evaluate the following checkpoints: ['models/EmbeddingGroups/CROSS-LINGUAL/lug_hau_nya/combined_afroxlmr']
09/01/2025 22:47:07 - INFO - __main__ -   Loading features from cached file data/EmbeddingGroups/CROSS-LINGUAL/lug_hau_nya/COMBINED/cached_dev_afro-xlmr-base_164
09/01/2025 22:47:08 - INFO - __main__ -   ***** Running evaluation  *****
09/01/2025 22:47:08 - INFO - __main__ -     Num examples = 7498
09/01/2025 22:47:08 - INFO - __main__ -     Batch size = 8
Evaluating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 938/938 [00:09<00:00, 94.98it/s]
09/01/2025 22:47:18 - INFO - __main__ -   ***** Eval results  *****
09/01/2025 22:47:18 - INFO - __main__ -     f1 = 0.8293208767517067
09/01/2025 22:47:18 - INFO - __main__ -     loss = 0.06213668621320157
09/01/2025 22:47:18 - INFO - __main__ -     precision = 0.8138222849083215
09/01/2025 22:47:18 - INFO - __main__ -     recall = 0.8454212454212454
09/01/2025 22:47:18 - INFO - __main__ -     report =               precision    recall  f1-score   support

        DATE       0.76      0.79      0.77       434
         LOC       0.87      0.90      0.88       688
         ORG       0.70      0.70      0.70       156
         PER       0.86      0.95      0.91        87

   micro avg       0.81      0.85      0.83      1365
   macro avg       0.80      0.84      0.82      1365
weighted avg       0.81      0.85      0.83      1365

09/01/2025 22:47:19 - INFO - __main__ -   Loading features from cached file data/EmbeddingGroups/CROSS-LINGUAL/lug_hau_nya/COMBINED/cached_test_afro-xlmr-base_164
09/01/2025 22:47:19 - INFO - __main__ -   ***** Running evaluation  *****
09/01/2025 22:47:19 - INFO - __main__ -     Num examples = 7508
09/01/2025 22:47:19 - INFO - __main__ -     Batch size = 8
Evaluating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 939/939 [00:09<00:00, 94.20it/s]
09/01/2025 22:47:30 - INFO - __main__ -   ***** Eval results  *****
09/01/2025 22:47:30 - INFO - __main__ -     f1 = 0.8271092669432919
09/01/2025 22:47:30 - INFO - __main__ -     loss = 0.0620111766070474
09/01/2025 22:47:30 - INFO - __main__ -     precision = 0.8169398907103825
09/01/2025 22:47:30 - INFO - __main__ -     recall = 0.8375350140056023
09/01/2025 22:47:30 - INFO - __main__ -     report =               precision    recall  f1-score   support

        DATE       0.75      0.78      0.76       437
         LOC       0.88      0.90      0.89       715
         ORG       0.69      0.70      0.69       162
         PER       0.83      0.89      0.86       114

   micro avg       0.82      0.84      0.83      1428
   macro avg       0.79      0.82      0.80      1428
weighted avg       0.82      0.84      0.83      1428

Starting training with mBERT...
/home/prosper/miniconda3/envs/runyankore-ner/lib/python3.10/site-packages/huggingface_hub/file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
09/01/2025 22:47:32 - INFO - __main__ -   Training/evaluation parameters Namespace(data_dir='data/EmbeddingGroups/CROSS-LINGUAL/lug_hau_nya/COMBINED/', model_type='bert', model_name_or_path='bert-base-multilingual-cased', input_dir=None, output_dir='models/EmbeddingGroups/CROSS-LINGUAL/lug_hau_nya/combined_mbert', test_result_file='test_results.txt', test_prediction_file='test_predictions.txt', labels='', config_name='', tokenizer_name='', cache_dir='', max_seq_length=164, do_train=True, do_finetune=False, do_eval=True, do_predict=True, evaluate_during_training=False, do_lower_case=False, per_gpu_train_batch_size=32, per_gpu_eval_batch_size=8, gradient_accumulation_steps=1, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=10.0, max_steps=-1, warmup_steps=0, logging_steps=500, save_steps=5000, eval_all_checkpoints=False, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=1, local_rank=-1, server_ip='', server_port='', n_gpu=1, device=device(type='cuda'))
09/01/2025 22:47:32 - INFO - __main__ -   Loading features from cached file data/EmbeddingGroups/CROSS-LINGUAL/lug_hau_nya/COMBINED/cached_train_bert-base-multilingual-cased_164
/home/prosper/miniconda3/envs/runyankore-ner/lib/python3.10/site-packages/transformers/optimization.py:588: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
09/01/2025 22:47:34 - INFO - __main__ -   ***** Running training *****
09/01/2025 22:47:34 - INFO - __main__ -     Num examples = 31909
09/01/2025 22:47:34 - INFO - __main__ -     Num Epochs = 10
09/01/2025 22:47:34 - INFO - __main__ -     Instantaneous batch size per GPU = 32
09/01/2025 22:47:34 - INFO - __main__ -     Total train batch size (w. parallel, distributed & accumulation) = 32
09/01/2025 22:47:34 - INFO - __main__ -     Gradient Accumulation steps = 1
09/01/2025 22:47:34 - INFO - __main__ -     Total optimization steps = 9980
Epoch:   0%|                                                                                                                                                           | 0/10 [00:00<?, ?it/s/home/prosper/miniconda3/envs/runyankore-ner/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:182: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn(
Iteration: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 998/998 [01:34<00:00, 10.57it/s]
09/01/2025 22:49:08 - INFO - __main__ -   Loading features from cached file data/EmbeddingGroups/CROSS-LINGUAL/lug_hau_nya/COMBINED/cached_dev_bert-base-multilingual-cased_164:00, 10.53it/s]
09/01/2025 22:49:09 - INFO - __main__ -   ***** Running evaluation  *****
09/01/2025 22:49:09 - INFO - __main__ -     Num examples = 7498
09/01/2025 22:49:09 - INFO - __main__ -     Batch size = 8
Evaluating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 938/938 [00:09<00:00, 94.43it/s]
eval result:  998 0.73288██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████ | 932/938 [00:09<00:00, 70.27it/s]
09/01/2025 22:49:20 - INFO - __main__ -   Saving model checkpoint to models/EmbeddingGroups/CROSS-LINGUAL/lug_hau_nya/combined_mbert
Iteration: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 998/998 [01:34<00:00, 10.58it/s]
09/01/2025 22:50:54 - INFO - __main__ -   Loading features from cached file data/EmbeddingGroups/CROSS-LINGUAL/lug_hau_nya/COMBINED/cached_dev_bert-base-multilingual-cased_164:00, 11.73it/s]
09/01/2025 22:50:55 - INFO - __main__ -   ***** Running evaluation  *****
09/01/2025 22:50:55 - INFO - __main__ -     Num examples = 7498
09/01/2025 22:50:55 - INFO - __main__ -     Batch size = 8
Evaluating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 938/938 [00:09<00:00, 99.38it/s]
eval result:  1996 0.79221██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 938/938 [00:09<00:00, 71.04it/s]
09/01/2025 22:51:05 - INFO - __main__ -   Saving model checkpoint to models/EmbeddingGroups/CROSS-LINGUAL/lug_hau_nya/combined_mbert
Iteration: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 998/998 [01:34<00:00, 10.56it/s]
09/01/2025 22:52:40 - INFO - __main__ -   Loading features from cached file data/EmbeddingGroups/CROSS-LINGUAL/lug_hau_nya/COMBINED/cached_dev_bert-base-multilingual-cased_164:00, 11.69it/s]
09/01/2025 22:52:40 - INFO - __main__ -   ***** Running evaluation  *****
09/01/2025 22:52:40 - INFO - __main__ -     Num examples = 7498
09/01/2025 22:52:40 - INFO - __main__ -     Batch size = 8
Evaluating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 938/938 [00:09<00:00, 98.46it/s]
eval result:  2994 0.77719█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋| 936/938 [00:09<00:00, 67.86it/s]
Iteration: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 998/998 [01:34<00:00, 10.56it/s]
09/01/2025 22:54:25 - INFO - __main__ -   Loading features from cached file data/EmbeddingGroups/CROSS-LINGUAL/lug_hau_nya/COMBINED/cached_dev_bert-base-multilingual-cased_164:00, 11.63it/s]
09/01/2025 22:54:25 - INFO - __main__ -   ***** Running evaluation  *****
09/01/2025 22:54:25 - INFO - __main__ -     Num examples = 7498
09/01/2025 22:54:25 - INFO - __main__ -     Batch size = 8
Evaluating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 938/938 [00:09<00:00, 99.68it/s]
eval result:  3992 0.80171██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 938/938 [00:09<00:00, 71.37it/s]
09/01/2025 22:54:36 - INFO - __main__ -   Saving model checkpoint to models/EmbeddingGroups/CROSS-LINGUAL/lug_hau_nya/combined_mbert
Iteration: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 998/998 [01:34<00:00, 10.56it/s]
09/01/2025 22:56:10 - INFO - __main__ -   Loading features from cached file data/EmbeddingGroups/CROSS-LINGUAL/lug_hau_nya/COMBINED/cached_dev_bert-base-multilingual-cased_164:00, 11.64it/s]
09/01/2025 22:56:10 - INFO - __main__ -   ***** Running evaluation  *****
09/01/2025 22:56:10 - INFO - __main__ -     Num examples = 7498
09/01/2025 22:56:10 - INFO - __main__ -     Batch size = 8
Evaluating: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 938/938 [00:09<00:00, 100.04it/s]
eval result:  4990 0.80468█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████ | 932/938 [00:09<00:00, 70.73it/s]
09/01/2025 22:56:21 - INFO - __main__ -   Saving model checkpoint to models/EmbeddingGroups/CROSS-LINGUAL/lug_hau_nya/combined_mbert
Iteration: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 998/998 [01:34<00:00, 10.58it/s]
09/01/2025 22:57:55 - INFO - __main__ -   Loading features from cached file data/EmbeddingGroups/CROSS-LINGUAL/lug_hau_nya/COMBINED/cached_dev_bert-base-multilingual-cased_164:00, 11.70it/s]
09/01/2025 22:57:56 - INFO - __main__ -   ***** Running evaluation  *****
09/01/2025 22:57:56 - INFO - __main__ -     Num examples = 7498
09/01/2025 22:57:56 - INFO - __main__ -     Batch size = 8
Evaluating: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 938/938 [00:09<00:00, 100.06it/s]
eval result:  5988 0.80585█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎| 933/938 [00:09<00:00, 70.80it/s]
09/01/2025 22:58:06 - INFO - __main__ -   Saving model checkpoint to models/EmbeddingGroups/CROSS-LINGUAL/lug_hau_nya/combined_mbert
Iteration: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 998/998 [01:34<00:00, 10.57it/s]
09/01/2025 22:59:41 - INFO - __main__ -   Loading features from cached file data/EmbeddingGroups/CROSS-LINGUAL/lug_hau_nya/COMBINED/cached_dev_bert-base-multilingual-cased_164:00, 11.67it/s]
09/01/2025 22:59:41 - INFO - __main__ -   ***** Running evaluation  *****
09/01/2025 22:59:41 - INFO - __main__ -     Num examples = 7498
09/01/2025 22:59:41 - INFO - __main__ -     Batch size = 8
Evaluating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 938/938 [00:09<00:00, 99.43it/s]
eval result:  6986 0.80429████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉ | 931/938 [00:09<00:00, 70.75it/s]
Iteration: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 998/998 [01:34<00:00, 10.57it/s]
09/01/2025 23:01:25 - INFO - __main__ -   Loading features from cached file data/EmbeddingGroups/CROSS-LINGUAL/lug_hau_nya/COMBINED/cached_dev_bert-base-multilingual-cased_164:00, 11.68it/s]
09/01/2025 23:01:26 - INFO - __main__ -   ***** Running evaluation  *****
09/01/2025 23:01:26 - INFO - __main__ -     Num examples = 7498
09/01/2025 23:01:26 - INFO - __main__ -     Batch size = 8
Evaluating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 938/938 [00:09<00:00, 99.95it/s]
eval result:  7984 0.81368█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎| 933/938 [00:09<00:00, 70.55it/s]
09/01/2025 23:01:36 - INFO - __main__ -   Saving model checkpoint to models/EmbeddingGroups/CROSS-LINGUAL/lug_hau_nya/combined_mbert
Iteration: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 998/998 [01:34<00:00, 10.57it/s]
09/01/2025 23:03:11 - INFO - __main__ -   Loading features from cached file data/EmbeddingGroups/CROSS-LINGUAL/lug_hau_nya/COMBINED/cached_dev_bert-base-multilingual-cased_164:00, 11.69it/s]
09/01/2025 23:03:11 - INFO - __main__ -   ***** Running evaluation  *****
09/01/2025 23:03:11 - INFO - __main__ -     Num examples = 7498
09/01/2025 23:03:11 - INFO - __main__ -     Batch size = 8
Evaluating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 938/938 [00:09<00:00, 99.34it/s]
eval result:  8982 0.81778█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊| 937/938 [00:09<00:00, 70.08it/s]
09/01/2025 23:03:22 - INFO - __main__ -   Saving model checkpoint to models/EmbeddingGroups/CROSS-LINGUAL/lug_hau_nya/combined_mbert
Iteration: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 998/998 [01:34<00:00, 10.56it/s]
09/01/2025 23:04:56 - INFO - __main__ -   Loading features from cached file data/EmbeddingGroups/CROSS-LINGUAL/lug_hau_nya/COMBINED/cached_dev_bert-base-multilingual-cased_164:00, 11.66it/s]
09/01/2025 23:04:57 - INFO - __main__ -   ***** Running evaluation  *****
09/01/2025 23:04:57 - INFO - __main__ -     Num examples = 7498
09/01/2025 23:04:57 - INFO - __main__ -     Batch size = 8
Evaluating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 938/938 [00:09<00:00, 99.84it/s]
eval result:  9980 0.8196██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████ | 932/938 [00:09<00:00, 70.44it/s]
09/01/2025 23:05:07 - INFO - __main__ -   Saving model checkpoint to models/EmbeddingGroups/CROSS-LINGUAL/lug_hau_nya/combined_mbert
Epoch: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [17:33<00:00, 105.31s/it]
09/01/2025 23:05:07 - INFO - __main__ -   Loading features from cached file data/EmbeddingGroups/CROSS-LINGUAL/lug_hau_nya/COMBINED/cached_dev_bert-base-multilingual-cased_164
09/01/2025 23:05:07 - INFO - __main__ -   ***** Running evaluation  *****
09/01/2025 23:05:07 - INFO - __main__ -     Num examples = 7498
09/01/2025 23:05:07 - INFO - __main__ -     Batch size = 8
Evaluating: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 938/938 [00:09<00:00, 100.23it/s]
09/01/2025 23:05:17 - INFO - __main__ -    global_step = 9980, average loss = 0.02849128591830024
09/01/2025 23:05:17 - INFO - __main__ -   Saving model checkpoint to models/EmbeddingGroups/CROSS-LINGUAL/lug_hau_nya/combined_mbert
09/01/2025 23:05:18 - INFO - __main__ -   Evaluate the following checkpoints: ['models/EmbeddingGroups/CROSS-LINGUAL/lug_hau_nya/combined_mbert']
09/01/2025 23:05:18 - INFO - __main__ -   Loading features from cached file data/EmbeddingGroups/CROSS-LINGUAL/lug_hau_nya/COMBINED/cached_dev_bert-base-multilingual-cased_164
09/01/2025 23:05:19 - INFO - __main__ -   ***** Running evaluation  *****
09/01/2025 23:05:19 - INFO - __main__ -     Num examples = 7498
09/01/2025 23:05:19 - INFO - __main__ -     Batch size = 8
Evaluating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 938/938 [00:09<00:00, 99.83it/s]
09/01/2025 23:05:28 - INFO - __main__ -   ***** Eval results  *****
09/01/2025 23:05:28 - INFO - __main__ -     f1 = 0.8196007259528131
09/01/2025 23:05:28 - INFO - __main__ -     loss = 0.07043600562070979
09/01/2025 23:05:28 - INFO - __main__ -     precision = 0.8122302158273381
09/01/2025 23:05:28 - INFO - __main__ -     recall = 0.827106227106227
09/01/2025 23:05:28 - INFO - __main__ -     report =               precision    recall  f1-score   support

        DATE       0.76      0.78      0.77       434
         LOC       0.86      0.87      0.87       688
         ORG       0.72      0.70      0.71       156
         PER       0.82      0.92      0.87        87

   micro avg       0.81      0.83      0.82      1365
   macro avg       0.79      0.82      0.80      1365
weighted avg       0.81      0.83      0.82      1365

09/01/2025 23:05:29 - INFO - __main__ -   Loading features from cached file data/EmbeddingGroups/CROSS-LINGUAL/lug_hau_nya/COMBINED/cached_test_bert-base-multilingual-cased_164
09/01/2025 23:05:29 - INFO - __main__ -   ***** Running evaluation  *****
09/01/2025 23:05:29 - INFO - __main__ -     Num examples = 7508
09/01/2025 23:05:29 - INFO - __main__ -     Batch size = 8
Evaluating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 939/939 [00:09<00:00, 99.72it/s]
09/01/2025 23:05:39 - INFO - __main__ -   ***** Eval results  *****
09/01/2025 23:05:39 - INFO - __main__ -     f1 = 0.8106427090532136
09/01/2025 23:05:39 - INFO - __main__ -     loss = 0.07428623029391677
09/01/2025 23:05:39 - INFO - __main__ -     precision = 0.8001364256480218
09/01/2025 23:05:39 - INFO - __main__ -     recall = 0.8214285714285714
09/01/2025 23:05:39 - INFO - __main__ -     report =               precision    recall  f1-score   support

        DATE       0.72      0.74      0.73       437
         LOC       0.86      0.89      0.87       715
         ORG       0.75      0.72      0.74       162
         PER       0.79      0.88      0.83       114

   micro avg       0.80      0.82      0.81      1428
   macro avg       0.78      0.81      0.79      1428
weighted avg       0.80      0.82      0.81      1428

Starting training with XLM-R...
/home/prosper/miniconda3/envs/runyankore-ner/lib/python3.10/site-packages/huggingface_hub/file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
09/01/2025 23:05:42 - INFO - __main__ -   Training/evaluation parameters Namespace(data_dir='data/EmbeddingGroups/CROSS-LINGUAL/lug_hau_nya/COMBINED/', model_type='xlmroberta', model_name_or_path='xlm-roberta-base', input_dir=None, output_dir='models/EmbeddingGroups/CROSS-LINGUAL/lug_hau_nya/combined_xlmr', test_result_file='test_results.txt', test_prediction_file='test_predictions.txt', labels='', config_name='', tokenizer_name='', cache_dir='', max_seq_length=164, do_train=True, do_finetune=False, do_eval=True, do_predict=True, evaluate_during_training=False, do_lower_case=False, per_gpu_train_batch_size=32, per_gpu_eval_batch_size=8, gradient_accumulation_steps=1, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=10.0, max_steps=-1, warmup_steps=0, logging_steps=500, save_steps=5000, eval_all_checkpoints=False, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=1, local_rank=-1, server_ip='', server_port='', n_gpu=1, device=device(type='cuda'))
09/01/2025 23:05:42 - INFO - __main__ -   Loading features from cached file data/EmbeddingGroups/CROSS-LINGUAL/lug_hau_nya/COMBINED/cached_train_xlm-roberta-base_164
/home/prosper/miniconda3/envs/runyankore-ner/lib/python3.10/site-packages/transformers/optimization.py:588: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
09/01/2025 23:05:44 - INFO - __main__ -   ***** Running training *****
09/01/2025 23:05:44 - INFO - __main__ -     Num examples = 31909
09/01/2025 23:05:44 - INFO - __main__ -     Num Epochs = 10
09/01/2025 23:05:44 - INFO - __main__ -     Instantaneous batch size per GPU = 32
09/01/2025 23:05:44 - INFO - __main__ -     Total train batch size (w. parallel, distributed & accumulation) = 32
09/01/2025 23:05:44 - INFO - __main__ -     Gradient Accumulation steps = 1
09/01/2025 23:05:44 - INFO - __main__ -     Total optimization steps = 9980
Epoch:   0%|                                                                                                                                                           | 0/10 [00:00<?, ?it/s/home/prosper/miniconda3/envs/runyankore-ner/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:182: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn(
Iteration: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 998/998 [01:50<00:00,  9.02it/s]
09/01/2025 23:07:34 - INFO - __main__ -   Creating features from dataset file at data/EmbeddingGroups/CROSS-LINGUAL/lug_hau_nya/COMBINED/██████████████████▊| 997/998 [01:50<00:00,  9.04it/s]
09/01/2025 23:07:34 - INFO - utils_ner -   Writing example 0 of 7498
09/01/2025 23:07:34 - INFO - utils_ner -   *** Example ***
09/01/2025 23:07:34 - INFO - utils_ner -   guid: dev-1
09/01/2025 23:07:34 - INFO - utils_ner -   tokens: <s> ▁Eis home ro ▁ry a handi ika ▁ripoti ▁ye ▁er izo oba ▁ . </s>
09/01/2025 23:07:34 - INFO - utils_ner -   input_ids: 0 104331 29552 516 5535 11 146625 2959 187326 2422 72 33602 16159 6 5 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
09/01/2025 23:07:34 - INFO - utils_ner -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
09/01/2025 23:07:34 - INFO - utils_ner -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
09/01/2025 23:07:34 - INFO - utils_ner -   label_ids: -100 0 -100 -100 0 -100 -100 -100 0 0 1 -100 -100 0 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100
09/01/2025 23:07:34 - INFO - utils_ner -   *** Example ***
09/01/2025 23:07:34 - INFO - utils_ner -   guid: dev-2
09/01/2025 23:07:34 - INFO - utils_ner -   tokens: <s> ▁A kasi ngwa ▁om u ▁karu uru ▁om wa ka ▁og uh wa ire ▁ . </s>
09/01/2025 23:07:34 - INFO - utils_ner -   input_ids: 0 62 58801 95560 171 34 102377 12894 171 634 161 60 5951 634 2149 6 5 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
09/01/2025 23:07:34 - INFO - utils_ner -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
09/01/2025 23:07:34 - INFO - utils_ner -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
09/01/2025 23:07:34 - INFO - utils_ner -   label_ids: -100 0 -100 -100 0 -100 0 -100 1 -100 -100 2 -100 -100 -100 0 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100
09/01/2025 23:07:34 - INFO - utils_ner -   *** Example ***
09/01/2025 23:07:34 - INFO - utils_ner -   guid: dev-3
09/01/2025 23:07:34 - INFO - utils_ner -   tokens: <s> ▁Ok w ombe ka ▁o ruti ndo ▁ , ▁ni kwi ija ▁kut wara ▁em yaka ▁es hat u ▁ . </s>
09/01/2025 23:07:34 - INFO - utils_ner -   input_ids: 0 9972 434 54013 161 36 97387 557 6 4 300 96855 4391 28600 63991 352 122669 198 2943 34 6 5 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
09/01/2025 23:07:34 - INFO - utils_ner -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
09/01/2025 23:07:34 - INFO - utils_ner -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
09/01/2025 23:07:34 - INFO - utils_ner -   label_ids: -100 0 -100 -100 -100 0 -100 -100 0 -100 0 -100 -100 0 -100 1 -100 2 -100 -100 0 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100
09/01/2025 23:07:34 - INFO - utils_ner -   *** Example ***
09/01/2025 23:07:34 - INFO - utils_ner -   guid: dev-4
09/01/2025 23:07:34 - INFO - utils_ner -   tokens: <s> ▁Om wo jo ▁aka itwa ▁iba are ▁eru kiri ▁or wab aire ▁or wahi ring itsi re ▁om wa ka ▁og wa ▁h wa ire ▁ . </s>
09/01/2025 23:07:34 - INFO - utils_ner -   input_ids: 0 2383 3613 513 15623 122448 7824 1046 3599 27531 707 72947 9459 707 71387 2852 30241 107 171 634 161 60 634 1096 634 2149 6 5 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
09/01/2025 23:07:34 - INFO - utils_ner -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
09/01/2025 23:07:34 - INFO - utils_ner -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
09/01/2025 23:07:34 - INFO - utils_ner -   label_ids: -100 0 -100 -100 0 -100 0 -100 0 -100 0 -100 -100 0 -100 -100 -100 -100 1 -100 -100 2 -100 2 -100 -100 0 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100
09/01/2025 23:07:34 - INFO - utils_ner -   *** Example ***
09/01/2025 23:07:34 - INFO - utils_ner -   guid: dev-5
09/01/2025 23:07:34 - INFO - utils_ner -   tokens: <s> ▁Om web embe zi ▁w ' ei hanga ▁aka kinga ▁a makan isa ▁okuma ra ▁e bir o ▁maku mi ▁muka aga ▁e bind i ▁ . </s>
09/01/2025 23:07:34 - INFO - utils_ner -   input_ids: 0 2383 14051 55720 708 148 25 1399 58146 15623 107546 10 54082 4542 97405 219 28 5720 31 62332 266 14330 4729 28 89817 14 6 5 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
09/01/2025 23:07:34 - INFO - utils_ner -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
09/01/2025 23:07:34 - INFO - utils_ner -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
09/01/2025 23:07:34 - INFO - utils_ner -   label_ids: -100 0 -100 -100 -100 0 -100 -100 -100 0 -100 0 -100 -100 0 -100 1 -100 -100 2 -100 2 -100 0 -100 -100 0 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100
09/01/2025 23:07:35 - INFO - __main__ -   Saving features into cached file data/EmbeddingGroups/CROSS-LINGUAL/lug_hau_nya/COMBINED/cached_dev_xlm-roberta-base_164
09/01/2025 23:07:36 - INFO - __main__ -   ***** Running evaluation  *****
09/01/2025 23:07:36 - INFO - __main__ -     Num examples = 7498
09/01/2025 23:07:36 - INFO - __main__ -     Batch size = 8
Evaluating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 938/938 [00:10<00:00, 92.17it/s]
eval result:  998 0.75018██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌| 935/938 [00:10<00:00, 66.02it/s]
09/01/2025 23:07:48 - INFO - __main__ -   Saving model checkpoint to models/EmbeddingGroups/CROSS-LINGUAL/lug_hau_nya/combined_xlmr
Iteration: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 998/998 [01:50<00:00,  9.03it/s]
09/01/2025 23:09:38 - INFO - __main__ -   Loading features from cached file data/EmbeddingGroups/CROSS-LINGUAL/lug_hau_nya/COMBINED/cached_dev_xlm-roberta-base_16498 [01:50<00:00,  9.02it/s]
09/01/2025 23:09:39 - INFO - __main__ -   ***** Running evaluation  *****
09/01/2025 23:09:39 - INFO - __main__ -     Num examples = 7498
09/01/2025 23:09:39 - INFO - __main__ -     Batch size = 8
Evaluating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 938/938 [00:09<00:00, 93.91it/s]
eval result:  1996 0.75316█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌| 935/938 [00:09<00:00, 67.25it/s]
09/01/2025 23:09:50 - INFO - __main__ -   Saving model checkpoint to models/EmbeddingGroups/CROSS-LINGUAL/lug_hau_nya/combined_xlmr
Iteration: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 998/998 [01:50<00:00,  9.03it/s]
09/01/2025 23:11:41 - INFO - __main__ -   Loading features from cached file data/EmbeddingGroups/CROSS-LINGUAL/lug_hau_nya/COMBINED/cached_dev_xlm-roberta-base_16498 [01:50<00:00,  9.04it/s]
09/01/2025 23:11:41 - INFO - __main__ -   ***** Running evaluation  *****
09/01/2025 23:11:41 - INFO - __main__ -     Num examples = 7498
09/01/2025 23:11:41 - INFO - __main__ -     Batch size = 8
Evaluating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 938/938 [00:10<00:00, 92.85it/s]
eval result:  2994 0.77978█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋| 936/938 [00:10<00:00, 67.34it/s]
09/01/2025 23:11:53 - INFO - __main__ -   Saving model checkpoint to models/EmbeddingGroups/CROSS-LINGUAL/lug_hau_nya/combined_xlmr
Iteration: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 998/998 [01:50<00:00,  9.03it/s]
09/01/2025 23:13:43 - INFO - __main__ -   Loading features from cached file data/EmbeddingGroups/CROSS-LINGUAL/lug_hau_nya/COMBINED/cached_dev_xlm-roberta-base_16498 [01:50<00:00,  9.02it/s]
09/01/2025 23:13:43 - INFO - __main__ -   ***** Running evaluation  *****
09/01/2025 23:13:43 - INFO - __main__ -     Num examples = 7498
09/01/2025 23:13:43 - INFO - __main__ -     Batch size = 8
Evaluating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 938/938 [00:09<00:00, 94.26it/s]
eval result:  3992 0.79525█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊| 937/938 [00:09<00:00, 67.29it/s]
09/01/2025 23:13:55 - INFO - __main__ -   Saving model checkpoint to models/EmbeddingGroups/CROSS-LINGUAL/lug_hau_nya/combined_xlmr
Iteration: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 998/998 [01:50<00:00,  9.02it/s]
09/01/2025 23:15:46 - INFO - __main__ -   Loading features from cached file data/EmbeddingGroups/CROSS-LINGUAL/lug_hau_nya/COMBINED/cached_dev_xlm-roberta-base_16498 [01:50<00:00,  8.98it/s]
09/01/2025 23:15:46 - INFO - __main__ -   ***** Running evaluation  *****
09/01/2025 23:15:46 - INFO - __main__ -     Num examples = 7498
09/01/2025 23:15:46 - INFO - __main__ -     Batch size = 8
Evaluating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 938/938 [00:09<00:00, 93.96it/s]
eval result:  4990 0.79797█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍| 934/938 [00:09<00:00, 67.16it/s]
09/01/2025 23:15:57 - INFO - __main__ -   Saving model checkpoint to models/EmbeddingGroups/CROSS-LINGUAL/lug_hau_nya/combined_xlmr
Iteration: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 998/998 [01:50<00:00,  9.03it/s]
09/01/2025 23:17:48 - INFO - __main__ -   Loading features from cached file data/EmbeddingGroups/CROSS-LINGUAL/lug_hau_nya/COMBINED/cached_dev_xlm-roberta-base_16498 [01:50<00:00,  9.00it/s]
09/01/2025 23:17:48 - INFO - __main__ -   ***** Running evaluation  *****
09/01/2025 23:17:48 - INFO - __main__ -     Num examples = 7498
09/01/2025 23:17:48 - INFO - __main__ -     Batch size = 8
Evaluating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 938/938 [00:09<00:00, 94.01it/s]
eval result:  5988 0.81346█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎| 933/938 [00:09<00:00, 67.18it/s]
09/01/2025 23:18:00 - INFO - __main__ -   Saving model checkpoint to models/EmbeddingGroups/CROSS-LINGUAL/lug_hau_nya/combined_xlmr
Iteration: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 998/998 [01:50<00:00,  9.03it/s]
09/01/2025 23:19:50 - INFO - __main__ -   Loading features from cached file data/EmbeddingGroups/CROSS-LINGUAL/lug_hau_nya/COMBINED/cached_dev_xlm-roberta-base_16498 [01:50<00:00,  8.99it/s]
09/01/2025 23:19:51 - INFO - __main__ -   ***** Running evaluation  *****
09/01/2025 23:19:51 - INFO - __main__ -     Num examples = 7498
09/01/2025 23:19:51 - INFO - __main__ -     Batch size = 8
Evaluating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 938/938 [00:10<00:00, 93.48it/s]
eval result:  6986 0.78414████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉ | 931/938 [00:09<00:00, 67.19it/s]
Iteration: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 998/998 [01:50<00:00,  9.03it/s]
09/01/2025 23:21:52 - INFO - __main__ -   Loading features from cached file data/EmbeddingGroups/CROSS-LINGUAL/lug_hau_nya/COMBINED/cached_dev_xlm-roberta-base_16498 [01:50<00:00,  8.99it/s]
09/01/2025 23:21:52 - INFO - __main__ -   ***** Running evaluation  *****
09/01/2025 23:21:52 - INFO - __main__ -     Num examples = 7498
09/01/2025 23:21:52 - INFO - __main__ -     Batch size = 8
Evaluating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 938/938 [00:09<00:00, 94.03it/s]
eval result:  7984 0.81025█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌| 935/938 [00:09<00:00, 67.18it/s]
Iteration: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 998/998 [01:50<00:00,  9.03it/s]
09/01/2025 23:23:53 - INFO - __main__ -   Loading features from cached file data/EmbeddingGroups/CROSS-LINGUAL/lug_hau_nya/COMBINED/cached_dev_xlm-roberta-base_16498 [01:50<00:00,  9.04it/s]
09/01/2025 23:23:53 - INFO - __main__ -   ***** Running evaluation  *****
09/01/2025 23:23:53 - INFO - __main__ -     Num examples = 7498
09/01/2025 23:23:53 - INFO - __main__ -     Batch size = 8
Evaluating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 938/938 [00:10<00:00, 93.66it/s]
eval result:  8982 0.81596█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎| 933/938 [00:09<00:00, 67.05it/s]
09/01/2025 23:24:05 - INFO - __main__ -   Saving model checkpoint to models/EmbeddingGroups/CROSS-LINGUAL/lug_hau_nya/combined_xlmr
Iteration: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 998/998 [01:50<00:00,  9.03it/s]
09/01/2025 23:25:56 - INFO - __main__ -   Loading features from cached file data/EmbeddingGroups/CROSS-LINGUAL/lug_hau_nya/COMBINED/cached_dev_xlm-roberta-base_16498 [01:50<00:00,  9.04it/s]
09/01/2025 23:25:56 - INFO - __main__ -   ***** Running evaluation  *****
09/01/2025 23:25:56 - INFO - __main__ -     Num examples = 7498
09/01/2025 23:25:56 - INFO - __main__ -     Batch size = 8
Evaluating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 938/938 [00:10<00:00, 93.69it/s]
eval result:  9980 0.81779█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎| 933/938 [00:09<00:00, 67.14it/s]
09/01/2025 23:26:08 - INFO - __main__ -   Saving model checkpoint to models/EmbeddingGroups/CROSS-LINGUAL/lug_hau_nya/combined_xlmr
Epoch: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [20:24<00:00, 122.43s/it]
09/01/2025 23:26:08 - INFO - __main__ -   Loading features from cached file data/EmbeddingGroups/CROSS-LINGUAL/lug_hau_nya/COMBINED/cached_dev_xlm-roberta-base_164
09/01/2025 23:26:08 - INFO - __main__ -   ***** Running evaluation  *****
09/01/2025 23:26:08 - INFO - __main__ -     Num examples = 7498
09/01/2025 23:26:08 - INFO - __main__ -     Batch size = 8
Evaluating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 938/938 [00:09<00:00, 94.75it/s]
09/01/2025 23:26:19 - INFO - __main__ -    global_step = 9980, average loss = 0.032030428883130395
09/01/2025 23:26:19 - INFO - __main__ -   Saving model checkpoint to models/EmbeddingGroups/CROSS-LINGUAL/lug_hau_nya/combined_xlmr
09/01/2025 23:26:21 - INFO - __main__ -   Evaluate the following checkpoints: ['models/EmbeddingGroups/CROSS-LINGUAL/lug_hau_nya/combined_xlmr']
09/01/2025 23:26:21 - INFO - __main__ -   Loading features from cached file data/EmbeddingGroups/CROSS-LINGUAL/lug_hau_nya/COMBINED/cached_dev_xlm-roberta-base_164
09/01/2025 23:26:21 - INFO - __main__ -   ***** Running evaluation  *****
09/01/2025 23:26:21 - INFO - __main__ -     Num examples = 7498
09/01/2025 23:26:21 - INFO - __main__ -     Batch size = 8
Evaluating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 938/938 [00:09<00:00, 97.74it/s]
09/01/2025 23:26:31 - INFO - __main__ -   ***** Eval results  *****
09/01/2025 23:26:31 - INFO - __main__ -     f1 = 0.817790530846485
09/01/2025 23:26:31 - INFO - __main__ -     loss = 0.0662655806165367
09/01/2025 23:26:31 - INFO - __main__ -     precision = 0.8011243851018974
09/01/2025 23:26:31 - INFO - __main__ -     recall = 0.8351648351648352
09/01/2025 23:26:31 - INFO - __main__ -     report =               precision    recall  f1-score   support

        DATE       0.75      0.79      0.77       434
         LOC       0.86      0.88      0.87       688
         ORG       0.69      0.70      0.69       156
         PER       0.80      0.97      0.88        87

   micro avg       0.80      0.84      0.82      1365
   macro avg       0.77      0.83      0.80      1365
weighted avg       0.80      0.84      0.82      1365

09/01/2025 23:26:32 - INFO - __main__ -   Creating features from dataset file at data/EmbeddingGroups/CROSS-LINGUAL/lug_hau_nya/COMBINED/
09/01/2025 23:26:32 - INFO - utils_ner -   Writing example 0 of 7508
09/01/2025 23:26:32 - INFO - utils_ner -   *** Example ***
09/01/2025 23:26:32 - INFO - utils_ner -   guid: test-1
09/01/2025 23:26:32 - INFO - utils_ner -   tokens: <s> ▁Ti imu ▁y ' em iza ano ▁e ya ▁di si turik iti ▁ , ▁e kah ika ▁a ha ▁kamar i rizo ▁om wa ka ▁og uh wa ire ▁ . </s>
09/01/2025 23:26:32 - INFO - utils_ner -   input_ids: 0 2371 15608 113 25 195 7337 3922 28 395 45 172 101605 1890 6 4 28 6577 2959 10 528 21323 14 155946 171 634 161 60 5951 634 2149 6 5 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
09/01/2025 23:26:32 - INFO - utils_ner -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
09/01/2025 23:26:32 - INFO - utils_ner -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
09/01/2025 23:26:32 - INFO - utils_ner -   label_ids: -100 0 -100 0 -100 -100 -100 -100 0 -100 0 -100 -100 -100 0 -100 0 -100 -100 0 -100 0 -100 -100 1 -100 -100 2 -100 -100 -100 0 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100
09/01/2025 23:26:32 - INFO - utils_ner -   *** Example ***
09/01/2025 23:26:32 - INFO - utils_ner -   guid: test-2
09/01/2025 23:26:32 - INFO - utils_ner -   tokens: <s> ▁Sh wen kuru ▁wang ye ▁aka fa ▁aine ▁em yaka ▁kina na ▁na ▁muna na ▁e y ' o buku ru ▁ . </s>
09/01/2025 23:26:32 - INFO - utils_ner -   input_ids: 0 7525 11697 120209 37109 1033 15623 1021 59482 352 122669 24222 76 24 29279 76 28 53 25 31 107798 882 6 5 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
09/01/2025 23:26:32 - INFO - utils_ner -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
09/01/2025 23:26:32 - INFO - utils_ner -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
09/01/2025 23:26:32 - INFO - utils_ner -   label_ids: -100 0 -100 -100 0 -100 0 -100 0 1 -100 2 -100 2 2 -100 0 -100 -100 -100 -100 -100 0 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100
09/01/2025 23:26:32 - INFO - utils_ner -   *** Example ***
09/01/2025 23:26:32 - INFO - utils_ner -   guid: test-3
09/01/2025 23:26:32 - INFO - utils_ner -   tokens: <s> ▁E bi kwa to ▁e biri mu ▁za ▁m izay iro ▁maku mi ▁a tano ▁e by agu zir we ▁kuru ga ▁China ▁bi kaa kii rwa ▁en kumi ▁i biri ▁i kumi ▁na ▁muna na ▁ . </s>
09/01/2025 23:26:32 - INFO - utils_ner -   input_ids: 0 241 964 10521 188 28 35653 561 80 347 83571 8699 62332 266 10 35221 28 1272 26722 26679 1177 14178 208 9098 333 17227 7072 70627 22 87064 17 35653 17 87064 24 29279 76 6 5 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
09/01/2025 23:26:32 - INFO - utils_ner -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
09/01/2025 23:26:32 - INFO - utils_ner -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
09/01/2025 23:26:32 - INFO - utils_ner -   label_ids: -100 0 -100 -100 -100 0 -100 -100 0 0 -100 -100 0 -100 0 -100 0 -100 -100 -100 -100 0 -100 7 0 -100 -100 -100 1 -100 2 -100 2 -100 2 2 -100 0 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100
09/01/2025 23:26:32 - INFO - utils_ner -   *** Example ***
09/01/2025 23:26:32 - INFO - utils_ner -   guid: test-4
09/01/2025 23:26:32 - INFO - utils_ner -   tokens: <s> ▁Aku ruga ▁om u ▁is home ro ▁aine ▁em yaka ▁i kumi ▁na ▁muka aga ▁ . </s>
09/01/2025 23:26:32 - INFO - utils_ner -   input_ids: 0 8158 46892 171 34 83 29552 516 59482 352 122669 17 87064 24 14330 4729 6 5 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
09/01/2025 23:26:32 - INFO - utils_ner -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
09/01/2025 23:26:32 - INFO - utils_ner -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
09/01/2025 23:26:32 - INFO - utils_ner -   label_ids: -100 0 -100 0 -100 0 -100 -100 0 1 -100 2 -100 2 2 -100 0 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100
09/01/2025 23:26:32 - INFO - utils_ner -   *** Example ***
09/01/2025 23:26:32 - INFO - utils_ner -   guid: test-5
09/01/2025 23:26:32 - INFO - utils_ner -   tokens: <s> ▁Ny om web az yo ▁ni b wo ▁ah iki ze ▁em yaka ▁i kumi ▁na ▁muna ana </s>
09/01/2025 23:26:32 - INFO - utils_ner -   input_ids: 0 2949 306 14051 1828 1410 300 275 3613 1263 5898 731 352 122669 17 87064 24 29279 1500 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
09/01/2025 23:26:32 - INFO - utils_ner -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
09/01/2025 23:26:32 - INFO - utils_ner -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
09/01/2025 23:26:32 - INFO - utils_ner -   label_ids: -100 1 -100 -100 -100 -100 0 -100 -100 0 -100 -100 1 -100 2 -100 2 2 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100
09/01/2025 23:26:33 - INFO - __main__ -   Saving features into cached file data/EmbeddingGroups/CROSS-LINGUAL/lug_hau_nya/COMBINED/cached_test_xlm-roberta-base_164
09/01/2025 23:26:33 - INFO - __main__ -   ***** Running evaluation  *****
09/01/2025 23:26:33 - INFO - __main__ -     Num examples = 7508
09/01/2025 23:26:33 - INFO - __main__ -     Batch size = 8
Evaluating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 939/939 [00:09<00:00, 98.12it/s]
09/01/2025 23:26:43 - INFO - __main__ -   ***** Eval results  *****
09/01/2025 23:26:43 - INFO - __main__ -     f1 = 0.8181818181818183
09/01/2025 23:26:43 - INFO - __main__ -     loss = 0.06595259002480759
09/01/2025 23:26:43 - INFO - __main__ -     precision = 0.8048780487804879
09/01/2025 23:26:43 - INFO - __main__ -     recall = 0.8319327731092437
09/01/2025 23:26:43 - INFO - __main__ -     report =               precision    recall  f1-score   support

        DATE       0.74      0.77      0.75       437
         LOC       0.86      0.89      0.88       715
         ORG       0.71      0.71      0.71       162
         PER       0.85      0.87      0.86       114

   micro avg       0.80      0.83      0.82      1428
   macro avg       0.79      0.81      0.80      1428
weighted avg       0.80      0.83      0.82      1428

All training jobs completed.
